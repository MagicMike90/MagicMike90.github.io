{"data":{"site":{"siteMetadata":{"title":"Michael Blog","author":"Michael Luo"}},"markdownRemark":{"id":"4ec34c98-88c1-5e4f-a276-7673da70d19e","excerpt":"Microservice notes Domain-drive design It is very important to note that OOP is not only inheritance, interfaces, or anything else of the type. OOP’s main ideas…","html":"<h1>Microservice notes</h1>\n<h2>Domain-drive design</h2>\n<p>It is very important to note that OOP is not only inheritance, interfaces, or anything else of the type. OOP’s main ideas are as follows:</p>\n<ul>\n<li>Code alignment with the business</li>\n<li>Favoring of reuse</li>\n<li>Minimal coupling</li>\n</ul>\n<p>three are more prominent for efficient microservices:</p>\n<ul>\n<li>Context maps: These are the communication paths between microservices with appropriate interactions between microservices teams. After the analysis of the areas are already defined, the team can choose to be dependent on another team for domain language.</li>\n<li>Anti-corruption layer (ACL): This is the function that translates foreign concepts for an internal model to provide loose coupling between the domains.</li>\n<li>Interchange context: This provides an environment for both teams and discusses the meaning of each foreign term and translates the languages of microservices.</li>\n</ul>\n<h2>Independent deploy, update, scale and replace</h2>\n<h3>Update</h3>\n<ul>\n<li>Never share libraries between microservices</li>\n<li>Strong delimitation of microservice domains</li>\n<li>Establish a client-server relationship between microservices</li>\n<li>Deploy in separate containers</li>\n</ul>\n<h3>Scale</h3>\n<p><strong>The Scale Cube</strong>: 3 axis</p>\n<ul>\n<li>x-axis: horizontal decomposition: with the same application server replicated n times in full and in a balanced order of 1/n.</li>\n<li>y-axis: functional decomposition: a verb or route is used by the balancer to identify where to go with the request.</li>\n<li>z-axis: data partitioning: is very similar to the x-axis when it comes to scalability structure, as it distributes exactly the same code on each server. The big difference is that each server responds to a specific subset of data</li>\n</ul>\n<h2>Communication</h2>\n<table>\n<thead>\n<tr>\n<th></th>\n<th align=\"center\">One-to-One</th>\n<th align=\"right\">One-to-Many</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Synchronous</td>\n<td align=\"center\">Request/response</td>\n<td align=\"right\">-</td>\n</tr>\n<tr>\n<td>Asynchronous</td>\n<td align=\"center\">Notification</td>\n<td align=\"right\">publish/subsribe</td>\n</tr>\n<tr>\n<td></td>\n<td align=\"center\">Request/ async response</td>\n<td align=\"right\">publish/async responses</td>\n</tr>\n</tbody>\n</table>\n<h3>Synchronous</h3>\n<ul>\n<li>HTTP</li>\n<li>TCP</li>\n<li>WebSockets</li>\n<li>Sockets</li>\n<li>RPC</li>\n<li>SOAP</li>\n</ul>\n<h3>Asynchronous</h3>\n<p>For this approach, the message broker is just perfect. Some software applications appear a good choice for message brokers, such as RabbitMQ, ActiveMQ, ZeroMQ, Kafka, and Redis. Each of these options has its own peculiarities, some are faster, others are more resilient. Again, the business setting is going to determine which technology is used.</p>\n<h3>Mobile vs web endpoints</h3>\n<p>Problems such as speed and weight information in the web world are not very common; we cannot say the same for the mobile world.</p>\n<h3>Caching at the client level</h3>\n<p>request only passes to be processed on the backend, if really necessary. In other words, it tries to block direct access to the backend to requests that have already been implemented in the recent past.</p>\n<h3>Throttling for your client</h3>\n<ul>\n<li>Number of requests per minute from the same client</li>\n<li>Number of requests per second from the same client</li>\n<li>Number of requests per minute from the same client for similar information</li>\n<li>Number of requests per second for the same client for the same information</li>\n</ul>\n<h3>Identification of an anemic domain</h3>\n<ul>\n<li>The microservice cannot perform the tasks itself with only the data received</li>\n<li>The microservice needs to fetch data in more than one endpoint to perform a task</li>\n<li>The microservice does not have a self-sufficient entity model</li>\n<li>The microservice waits for the completion of a task in another microservice to follow up what you need to do</li>\n<li>The microservice needs to share resources with other external microservices; these resources can be cached to the sample database</li>\n</ul>\n<p>If the microservice being developed is one of those items, then it can be a weak area. If a microservice has two or more characteristics of those listed, then it is definitely an anemic domain.</p>\n<p>Anemic domains are very harmful to the microservices ecosystem, because they have a tendency to be multiplied in order to correct the technical debt generated by the deficiency in the composition of their respective domains.</p>\n<h3>Fat domain - AAA (Authentication, Authorization, and Accounting</h3>\n<p>The division of this fat domain can be held in two parts; the first part is AAAService and the second is UserService. Another approach is the AAA responsibility for a gateway API. The functional scalability and features of implementation with these separate domains is much more interesting for the growth of the product as a whol</p>\n<h2>Things to consider</h2>\n<p>Cost and scability:</p>\n<ul>\n<li>Programming languages</li>\n<li>Microservices frameworks</li>\n<li>Binary communication</li>\n<li>Message broker</li>\n<li>Caching tools</li>\n<li>Fail alert tools</li>\n<li>Locale proof performance</li>\n</ul>\n<h2>Death Start</h2>\n<p>The Death Star is an anti-pattern where there is communication between the recursion microservices, and making progress becomes extremely complicated or expensive for a product.</p>\n<h2>Message broker - Async communication between services</h2>\n<p>why not use this messaging for all types of communication between microservices?</p>\n<p>The answer to this question is quite simple. A message bus is a physical component within the stack of microservices. It needs to be scaled just like any other physical component-based data storage and cache. This means that with a high-volume message, the synchronous mode of communication could be committed to an unwanted delay in the responses of the processes.</p>\n<h3>Tools</h3>\n<ul>\n<li>ActiveMQ</li>\n<li>RabbitMQ</li>\n<li>Kafka</li>\n</ul>\n<h4>Caching tools</h4>\n<ul>\n<li>Memcached\nclassic process of using cache, Memcached is simple and practical to use. The performance of Memcached is fully linked to the use of memory. If Memcached uses the disc to register any data, the performance is seriously compromised; moreover, Memcached does not have any record of disk capacity and always depends on third-party tools for this.</li>\n<li>Redis</li>\n</ul>\n<h4>Fail alert tools</h4>\n<p>four major points of failure when it comes to microservices</p>\n<ul>\n<li>Performance - New Relic and Datadog</li>\n<li>Build - Jenkins, Travis</li>\n<li>Components - Nagios and Zabbix are also very useful for making aid work to health check endpoints.</li>\n<li>\n<p>Implementation failures - Sentry</p>\n<ul>\n<li>See the impact of new deployments in real time</li>\n<li>Provide support to specific users interrupted by an error</li>\n<li>Detect and thwart fraud as it’s attempted: unusual amounts of failures on purchases, authentication, and other critical areas</li>\n<li>External integrations</li>\n</ul>\n</li>\n</ul>\n<h3>Locale proof performance</h3>\n<ul>\n<li>Apache Benchmark</li>\n<li>WRK</li>\n<li>Locust</li>\n</ul>\n<h2>Internal Patterns</h2>\n<ul>\n<li>Developing the structure</li>\n<li>Caching strategies</li>\n<li>CQRS – query strategy</li>\n<li>Event sourcing – data integrity</li>\n</ul>\n<h2>CQRS(Command Query Responsibility Segregation)</h2>\n<p>As the name implies, it is about separating the responsibility of writing and reading of data. CQRS is a code pattern and not an architectural pattern.</p>\n<p><code class=\"language-text\">Will just scaling the application servers solve all our problems?</code></p>\n<ul>\n<li>Deadlocks, timeouts, and slowness mean that your database may be in too much demand.</li>\n<li>Complex queries can be performed to obtain database data. ORMs can add even more complexity to the data filtering process by mapping entities and filtering data by using joins in different tables.</li>\n<li>Content obsolescence could be true</li>\n</ul>\n<p>The CQRS teaches us the division of responsibility for writing and reading data, both conceptual and using different physical storages. This means that there will be separate means for recording and retrieving data from the databases. Queries are done synchronously in a separate denormalized database, and writes asynchronously to a normalized database. Caching first is still a type of CQRS implementation at the conceptual level.</p>\n<p><strong>Command</strong> will be responsible for modifying the state of the data in the application, <strong>Query</strong> is the operation responsible for retrieving information from the database.</p>\n<p><strong>Synchronization</strong>: The following are some strategies to keep the foundations of reading and recording synchronized, and it is necessary to choose the one that best meets your scenario:</p>\n<ul>\n<li>Automatic updating: All changes in the state of a given recording database raise a synchronous process to update on the bench</li>\n<li>Update possible: All state changes of a given recording database trigger an asynchronous process to update the reading bank, offering an eventual data consistency</li>\n<li>Controlled update: A regular process and schedule is raised to synchronize the databases</li>\n<li>Update on demand: Every query checks the consistency of the read base compared to the recording, and forces an update if it is out of date</li>\n</ul>\n<p>Any update is one of the most used strategies, because it assumes that any given displayed data may already be out of date, so it is not necessary to impose a synchronous update process.</p>\n<p><strong>Queueing</strong>: Many CQRS implementations may require a message broker for the processing of commands and events.</p>\n<h2>Event sourcing – data integrity</h2>\n<ul>\n<li>Each change in the current state of your database would be a new event in a stream that only allows inclusion.</li>\n<li>Each update on the table would generate a new line, the change of status</li>\n<li>uses the append only model for database records</li>\n</ul>\n<h2>Aggregator Microservice Design Pattern</h2>\n<p>Best practices:</p>\n<ul>\n<li>Segregated database: This allows us to better scale our application, especially in the data storage layer.</li>\n<li>Microservice encapsulation: This divides the microservices into two layers—Public Facing Services and Internal Services. Such a division allows for greater flexibility with respect to the signature microservices, as Internal Services can be modified more easily.</li>\n<li>Applied CQRS: With CQRS, unnecessary stress points on the application were removed.</li>\n<li>Applied event sourcing: With event sourcing, we are conducting a stream of information from a news article. This gives us a real vision of the history of each news article.</li>\n<li>Applied pattern very scalable: With a strong pattern and understanding of how to scale the aggregator pattern, we have a clear vision of how to avoid anti-patterns.</li>\n</ul>\n<p>Pros:</p>\n<ul>\n<li>Scalability of both the x-axis and z-axis</li>\n<li>Tunneling microservices</li>\n<li>Microservices signature flexibility to Internal Services</li>\n<li>Providing a single access point for microservices</li>\n</ul>\n<p>Cons:</p>\n<ul>\n<li>Complexity to orchestrate data</li>\n<li>Bottleneck anti-pattern</li>\n<li>Latency in communication between microservices</li>\n</ul>\n<h2>Proxy design pattern</h2>\n<ul>\n<li>Dumb proxy - the only goal is to provide a single endpoint to facilitate the application clients and encapsulate direct access to the routes of microservices.</li>\n<li>Smart proxy - The most commonly seen task being executed by a Smart proxy is the content modification.</li>\n</ul>\n<p>Pros:</p>\n<ul>\n<li>Practical data consumption by the application clients</li>\n<li>Ease of implementation</li>\n<li>Possibility of good programming techniques at proxy level, such as caching</li>\n<li>Encapsulation of access to microservices</li>\n<li>Control and diversion of requests</li>\n</ul>\n<p>Cons:</p>\n<ul>\n<li>Bottleneck</li>\n<li>Inappropriate change of response</li>\n<li>Obstruction in the identification of overload</li>\n</ul>\n<h2>Chained Microservice Design pattern</h2>\n<p><strong>Big Ball of Mud Anti-patern</strong>:developing microservices that we do not define well in the domains, which makes microservices dependent on one another to complete trivial tasks. This type of error generates a series of unnecessary calls between the microservices, creating complex problems of being corrected, such as latency and, in the worst cases, cyclic-deployed dependency.</p>\n<p>Main characteristics:</p>\n<ul>\n<li><strong>Poorly defined domain</strong>: The domain is badly defined, forcing a direct connection with other microservices. Access points to the microservice do not require enough data to process a task, which forces the inference of data, searching in other microservices.</li>\n<li><strong>Mandatory direct communication</strong>: When direct communication between microservices is mandatory for most tasks or for all tasks, there is a problem. This indicates that the microservice is anemic or that the application as a whole is poorly developed.</li>\n<li><strong>Deploy clustered</strong>: When a microservice cannot be sent for production because it needs another microservice all together, or when the change of internal signatures of a microservice causes others to collapse, there is a Death Star anti-pattern issue. Creating business dependencies between microservices means that processes are not automated and fluid.</li>\n</ul>\n<p><em>Solution</em>:\nCorrelation ID: A simple way to implement correlation ID using HTTP would be to send a UUID in the header of the requests and use this UUID as an identifier to write the logs.</p>\n<h3>Purest microservices</h3>\n<p>The microservices in your business design should be pure. This means that a microservice must be extremely small in its domain and fully capable of performing its function without outside interference from other microservices.</p>\n<p>Pros:</p>\n<ul>\n<li>Practical implementation</li>\n<li>Dynamism for business</li>\n<li>Independent scalability</li>\n<li>Encapsulation of access to microservices</li>\n</ul>\n<p>Cons:</p>\n<ul>\n<li>The possibility of latency points</li>\n<li>The difficulty in understanding data ownership</li>\n<li>The difficulty of debugging</li>\n</ul>\n<h2>Branch Microservice Design Pattern</h2>\n<p>Rules:</p>\n<ul>\n<li>The composition of the response using direct call chains cannot extend one direct call to another microservice</li>\n<li>If more values are required for the response, an aggregation logic is created that will trigger concurrent requests for as many chains as needed</li>\n</ul>\n<p>Internal communication within a microservice can be worked on in the following three ways:</p>\n<ul>\n<li>Sequential: No concurrency or parallelism. This means that when we have to send messages from the commands to the microservices, the entire process will be a sequence. If you need to execute four commands to compose the data, all of them will be executed in a sequence.</li>\n<li>Threads: In this case, both POSIX threads (pthreads) and green threads can be used. Controlling threads is often not simple for developers, and if a thread fails, data orchestration could be compromised. However, it is the most practical way because there is no need for any external components of the programming language to be used for creating some level of competition or parallelism in the execution of the commands.</li>\n<li>Message Broker: The use of a transactional message broker for transmitting sensitive data within a microservice is quite usual. The disadvantage is the addition of a physical component within a microservice. However, the advantage is the ability to execute strategies that offer more resiliency in data transmission. The simple fact of working with transactions is already a great resource.</li>\n</ul>\n<p>Pros:</p>\n<ul>\n<li>The flexibility of implementation</li>\n<li>Independent scalability</li>\n<li>Encapsulation of access to microservices</li>\n<li>Compositional ability and orchestration</li>\n</ul>\n<p>Cons:</p>\n<ul>\n<li>The possibility of latency points</li>\n<li>The difficulty in understanding data ownership</li>\n<li>The difficulty of debugging</li>\n</ul>\n<h2>Asynchronous messaing design pattern</h2>\n<p>Pros:</p>\n<ul>\n<li>Independent scalability</li>\n<li>Extreme scalability</li>\n<li>Lazy processing</li>\n<li>Encapsulation of accesses to microservices</li>\n</ul>\n<p>Cons:</p>\n<ul>\n<li>Complexity in the monitoring of requisitions</li>\n<li>Complexity of the initial understanding of the pattern</li>\n<li>Difficulty of debugging</li>\n</ul>\n<h2>replese piplelines</h2>\n<p>Build -> Unit Test -> Integration Test -> End-to-End test -> realse</p>\n<h2>Monitoring a single service</h2>\n<ul>\n<li><code class=\"language-text\">Active Monitoring</code>is when the server that is to be monitored sends the status information to the monitoring tool</li>\n<li><code class=\"language-text\">Passive Monitoring</code> is when the monitoring tool requests information about the state of the machine or application from the server</li>\n</ul>\n<h2>Multiple service instances per host</h2>\n<p><strong>Pros</strong>\nOne of the key benefits is that it uses resources efficiently. Multiple instances of the service share the server and its operating system. Another benefit of this pattern is the relatively rapid deployment of a microservice instance.</p>\n<p><strong>Cons</strong>\nA major disadvantage is that there is little to no isolation of instances of the service unless each service instance is a separate process. If the instances are not separated in different processes, an instance with errors could compromise the entire process, besides making the individual monitoring of instances impossible.</p>\n<h2>Service instance per host</h2>\n<ul>\n<li>\n<p>Service instance per VM: Each instance of a microservice is a VM, and the execution of this VM enables the microservice to work.</p>\n<ul>\n<li>Pros: One of the main benefits of VMs is that each instance of microservice runs in a completely isolated manner, having fixed CPU and memory consumption, without competing for resource consumption with other microservices. Another great benefit of this pattern is the encapsulation of the technology used in the development of microservices.</li>\n<li>Cons: Each service instance has the overhead of a full VM, including the operating system. Another disadvantage of this approach is that deploying and booting a new version of a microservice is often slow because the cost of booting operating systems using VMs can be high.</li>\n</ul>\n</li>\n<li>\n<p>Service instance per container: each microservice instance runs in a container unique to the instance.</p>\n<ul>\n<li>Pros: They isolate their instances of microservices from one another. Containers are easily monitored. In addition, similar to the VMs, the containers encapsulate the technology used to implement microservices. Unlike the virtual machines, the containers are lighter. The container images are usually very fast to build and initialize.</li>\n<li>Cons: There are some disadvantages to using containers. Containers are not as secure as VMs because they share the host operating system kernel with each other.Another disadvantage of the containers is the complexity of the infrastructure if they are not using any cloud platform that offers interesting mechanisms to manipulate the containers.</li>\n</ul>\n</li>\n</ul>","frontmatter":{"title":"Microservice Architecture Notes!","date":"July 30, 2019"}}},"pageContext":{"slug":"architecture-microservice","previous":{"fields":{"slug":"python-scrapy"},"frontmatter":{"title":"Notes for Scrapy!"}},"next":{"fields":{"slug":"react"},"frontmatter":{"title":"React Notes!"}}}}