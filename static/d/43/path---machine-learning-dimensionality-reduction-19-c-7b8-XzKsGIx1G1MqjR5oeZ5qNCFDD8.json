{"data":{"site":{"siteMetadata":{"title":"Michael Blog","author":"Michael Luo"}},"markdownRemark":{"id":"5f7cdab0-30ff-57cf-afbe-d6798ce8e282","excerpt":"Dimensionality Reduction Principal component analysis (PCA) It is an unsupervised linear transformation technique that is widely used across different fieldsâ€¦","html":"<h1>Dimensionality Reduction</h1>\n<h2>Principal component analysis (PCA)</h2>\n<p>It is an unsupervised linear transformation technique that is widely used across different fields, most prominently for dimensionality reduction.</p>\n<h2>Linear Discriminant Analysis (LDA)</h2>\n<p>It can be used as a technique for feature extraction to increase the computational efficientcy and reduce the degreee of over-fitting due to the curse of dimensionality in nonregularized models.</p>\n<h2>Kernel principal component analysis</h2>\n<p>It will transform data that is not linearly separable onto a new, lower-dimensional subspace that is suitable for linear classifiers</p>\n<p>Downside: This approach is computational expesnsive, but it can be overcome by kernel trick.</p>\n<p><strong>Radial Basis Function (RBF)</strong></p>","frontmatter":{"title":"Dimensionality Reduction Notes!","date":"January 31, 2019"}}},"pageContext":{"slug":"machine-learning-dimensionality-reduction","previous":{"fields":{"slug":"machine-learning-clustering-analysis"},"frontmatter":{"title":"Cluster Analysis Notes!"}},"next":{"fields":{"slug":"git-git"},"frontmatter":{"title":"Git Notes!"}}}}