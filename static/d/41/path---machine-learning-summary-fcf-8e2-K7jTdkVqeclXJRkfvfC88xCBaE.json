{"data":{"site":{"siteMetadata":{"title":"Michael Blog","author":"Michael Luo"}},"markdownRemark":{"id":"468ce9ae-9fd1-51df-800d-dd9500e32140","excerpt":"Summary of machine learning Common used machine learning algorithm Listed in order of increasing complexity: Logiistic regressiong K-nearest neighbors - Number…","html":"<h1>Summary of machine learning</h1>\n<h2>Common used machine learning algorithm</h2>\n<p>Listed in order of increasing complexity:</p>\n<ul>\n<li>Logiistic regressiong</li>\n<li>K-nearest neighbors - Number of nearest neighbors to average</li>\n<li>Decision trees - Splitting criterion, max depth or tree, minimum saples needed to make a split</li>\n<li>Kernel SVM - Kernel type, kernel coefficient, penalty parameter</li>\n<li>Random forest - Number of trees, number of features to split in each node, splitting criterion, minimum saples needed to make a split</li>\n<li>Boosting - Number of trees learning rate, max depth of tree, split in each node, splitting criterion, minimun samples needed to make a split</li>\n</ul>\n<h2>General procesdure</h2>\n<ul>\n<li><strong>Project Scoping / Data Collection</strong></li>\n<li><strong>Inspect &#x26; Explore</strong></li>\n<li>\n<p><strong>Data preprocessing</strong></p>\n<ul>\n<li>formating, cleaning and sampling</li>\n<li>Data Transformation:</li>\n<li>Scalling</li>\n<li>Label coding</li>\n<li>One hot encoding for categorical feature</li>\n</ul>\n</li>\n<li>\n<p><strong>Feature engineering</strong> :It is the process of transforming raw data into features that better represent the underlying problem to the predictive models, resulting in improved model accuracy on unseen data</p>\n<ul>\n<li>Indicator Variables</li>\n<li>Indicator variable from thresholds</li>\n<li>Indicator variable from multiple features</li>\n<li>Indicator variable for special events</li>\n<li>Indicator variable for groups of classes</li>\n<li>Interaction Features</li>\n<li>Sum of two features</li>\n<li>Difference between two features</li>\n<li>Product of two features</li>\n<li>Quotient of two features</li>\n<li>Feature Representation</li>\n<li>Date and time features</li>\n<li>Numeric to categorical mappings</li>\n<li>Grouping sparse classes</li>\n<li>Creating dummy variables</li>\n<li>External Data</li>\n<li>Time series data</li>\n<li>External API’s</li>\n<li>Geocoding</li>\n<li>Other sources of the same data</li>\n<li>Error Analysis (Post-Modeling)</li>\n<li>Start with larger errors</li>\n<li>Segment by classes</li>\n<li>Unsupervised clustering</li>\n<li>Ask colleagues or domain experts</li>\n</ul>\n</li>\n<li>\n<p><strong>Feature selection</strong></p>\n<ul>\n<li>It is a process where you automatically select those features in your data that contribute most to the prediction variable or output in which you are interested</li>\n</ul>\n</li>\n<li>\n<p><strong>Dimensionality reduction</strong></p>\n<ul>\n<li>PCA</li>\n</ul>\n</li>\n<li><strong>Split train and test data set</strong></li>\n<li><strong>Train data</strong></li>\n<li><strong>Model evaluation and hyperparameter tuning</strong></li>\n<li><strong>Save and deploy model</strong></li>\n</ul>\n<h2>Reference</h2>\n<p>Books:</p>\n<ul>\n<li>\n<p>Introduction to Machine Learning with Python</p>\n<ul>\n<li>review: get general ideas of how machine learning works</li>\n</ul>\n</li>\n<li>\n<p>Real-World Machine Learning</p>\n<ul>\n<li>review: books follows general procedure to implement a machine learning model</li>\n</ul>\n</li>\n<li>\n<p>Python Machine Learning</p>\n<ul>\n<li>review: it is a good book to advance machine learning knowledge with scikit-learn</li>\n</ul>\n</li>\n<li>\n<p>Pythoe Machine Learning Blueprints</p>\n<ul>\n<li>review: a good book to build a full stack machine learning system with serveral examples</li>\n</ul>\n</li>\n</ul>\n<p>Online courses:</p>\n<ul>\n<li>\n<p>Coursera - Machine Learning by Stanford University</p>\n<ul>\n<li>review: A free open class designed by Standford University, this course teaches machine learning knowledge from basis to advance.</li>\n</ul>\n</li>\n</ul>","frontmatter":{"title":"Summary of machine learning!","date":"January 31, 2019"}}},"pageContext":{"slug":"machine-learning-summary","previous":{"fields":{"slug":"machine-learning-intro"},"frontmatter":{"title":"Introduction of Machine Learning!"}},"next":{"fields":{"slug":"machine-learning-scikit-learn"},"frontmatter":{"title":"Scifit-learn notes!"}}}}