<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title><![CDATA[Michael Blog]]></title><description><![CDATA[A starter blog demonstrating what Gatsby can do.]]></description><link>https://gatsby-starter-blog-demo.netlify.com/</link><generator>RSS for Node</generator><lastBuildDate>Sat, 02 Feb 2019 12:02:17 GMT</lastBuildDate><item><title><![CDATA[No title]]></title><description><![CDATA[Notes for NodeJS Asynchronous batching and caching Batching 
If we are invoking an asynchronous function while there is still another one…]]></description><link>https://gatsby-starter-blog-demo.netlify.com/node-js-readme</link><guid isPermaLink="false">https://gatsby-starter-blog-demo.netlify.com/node-js-readme</guid><content:encoded>&lt;h1&gt;Notes for NodeJS&lt;/h1&gt;
&lt;h2&gt;Asynchronous batching and caching&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Batching&lt;/strong&gt;
If we are invoking an asynchronous function while there is still another one pending, we can attach callback to the already running operation, instead of creating a brand new request.&lt;/p&gt;
&lt;p&gt;Problems:
The faster the API, the fewer batched requests we get. Alought the API is fast enough, it still represents a factor in the resource load of an application.
Also, sometimes we can safely assume that the result of an API invocation will not change so often; therefore, a simple request batching willl not provide the best performance. In all these circumstances, the best candidate to reduce the load of an application and increase its responsiveness is definitely a more agressive caching pattern.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Catching&lt;/strong&gt;
As soon as a request completes, we store its result in the catch, which can be a variable, an entry in the database, or in a specialized catching server. Hence, the next time the API is invoked, the result can be retrieved immediately from the cache, insead of spawning another request.&lt;/p&gt;
&lt;h2&gt;Running CPU-bound tasks&lt;/h2&gt;
&lt;h2&gt;Scalability&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Three dimesions&lt;/strong&gt;
x-axis: Cloning
y-axis: Decomposing by service/functionality
z-axis: Splitting by data partition&lt;/p&gt;
&lt;p&gt;vertical scaling - adding more resources to a single machine
horizontal scaling - adding more machines to the infrastructure&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Cloning&lt;/strong&gt;&lt;/p&gt;</content:encoded></item><item><title><![CDATA[No title]]></title><description><![CDATA[NodeJS security Code injection Indentify code injections Avoid shell injection Database injection Avoid SQL injection Mitigate injection…]]></description><link>https://gatsby-starter-blog-demo.netlify.com/node-js-security</link><guid isPermaLink="false">https://gatsby-starter-blog-demo.netlify.com/node-js-security</guid><content:encoded>&lt;h1&gt;NodeJS security&lt;/h1&gt;
&lt;h2&gt;Code injection&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Indentify code injections&lt;/li&gt;
&lt;li&gt;Avoid shell injection&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Database injection&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Avoid SQL injection&lt;/li&gt;
&lt;li&gt;Mitigate injection attacks in NoSQL database&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Concurency&lt;/h2&gt;
&lt;h2&gt;Authendication&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Enforce password strenghth rules&lt;/li&gt;
&lt;li&gt;Move passowrd to server&lt;/li&gt;
&lt;li&gt;Password recovery&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;And other authetication layers&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Two factor authentication&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Session management&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Anonymize the sessionID&lt;/li&gt;
&lt;li&gt;Set time to live&lt;/li&gt;
&lt;li&gt;Re-create the session when the user logs in&lt;/li&gt;
&lt;li&gt;Bind the seesion to prevent hijacking&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Access control&lt;/h2&gt;
&lt;h2&gt;Deniel of service attack&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Avoid synchronous code&lt;/li&gt;
&lt;li&gt;Manage memory usage - read file size&lt;/li&gt;
&lt;li&gt;Avoid asymmetry&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Cross-site scripting (XSS)&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Reflected XSS: which is a form of XSS where the injected script is reflected off the web server&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Stored XSS: where the injected script is stored on the server and executes when rendering the web page.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;DOM XSS (the fore two consider as server-side execution issues, this one is considerted as client-side execution)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Prevent XSS through configuration of server&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Sanitize input foir relected/stored XSS&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Escape unstrustred data inserted into HTML element content&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Sanitize HTML with a libary&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Bleach&lt;/li&gt;
&lt;li&gt;Sanitizer&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Escape untrusted data inserted into HTML attributes&lt;/li&gt;
&lt;li&gt;Escape untrusted data inserted into JavaScript data values&lt;/li&gt;
&lt;li&gt;Escape JSON values in an HTML context and read the data with JSON.Parse&lt;/li&gt;
&lt;li&gt;Escape and validate untrusted data inserted into CSS property values&lt;/li&gt;
&lt;li&gt;Escape untrusted data insered into HTML url parameter values&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Sanitize input for DOM XSS&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Use DOM construction methods instead of HTML interpretation&lt;/li&gt;
&lt;li&gt;JavaScript and HTML encode before HTML subcontext&lt;/li&gt;
&lt;li&gt;Do not apply attribute encoding in DOM context&lt;/li&gt;
&lt;li&gt;Avoid execution subcontexts&lt;/li&gt;
&lt;li&gt;Do not apply css encoding in style context&lt;/li&gt;
&lt;li&gt;JavaScript and url encode when creating links&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Avoid cross-site request forgery (CSRF)&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Synchronize tokens as part of CSRF protection&lt;/li&gt;
&lt;li&gt;Avoid setting up common CSRF pitfalls&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Protect the data&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Understand data flow&lt;/li&gt;
&lt;li&gt;Protect client application and data&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Securely transfer data&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;TSL and SLL&lt;/li&gt;
&lt;li&gt;proper logs&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Secure data stored within the application&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Oversharing was a common configuration problem in LAMP stacks because Apache had a default directory-sharing configuration that tried to disallow files of a certain type.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Secure codebase&lt;/h2&gt;</content:encoded></item><item><title><![CDATA[No title]]></title><description><![CDATA[SOA VS Mircoservice Microservices are fine-grained SOA components. In other words, a single SOA
component can be decomposed in a number of…]]></description><link>https://gatsby-starter-blog-demo.netlify.com/microservices-readme</link><guid isPermaLink="false">https://gatsby-starter-blog-demo.netlify.com/microservices-readme</guid><content:encoded>&lt;h1&gt;SOA VS Mircoservice&lt;/h1&gt;
&lt;p&gt;Microservices are fine-grained SOA components. In other words, a single SOA
component can be decomposed in a number of microservices that can work together
in order to provide the same level of functionality&lt;/p&gt;
&lt;p&gt;J2EE is a technology stack that was designed to write SOA architectures as it
enforced enterprise standards. Java Naming and Directory Interface, Enterprise
Java Beans, and Enterprise Service Bus (ESB) were the ecosystems where SOA
applications were built and maintained. Although ESB is a standard, very few
engineers who graduated after 2005 have heard about ESB, even fewer have used it,
and nowadays the modern frameworks such as Ruby on Rails do not even consider
such complex pieces of software.&lt;/p&gt;
&lt;h1&gt;NodeJS drawback&lt;/h1&gt;
&lt;p&gt;Due to it uses sigle tread, it results in bad performance on CPU intensive computing (concurrent computing or grid computing)&lt;/p&gt;</content:encoded></item><item><title><![CDATA[No title]]></title><description><![CDATA[Feature Engineering Identifying Important Features In Random Forests NOTE:  there are two things to keep in mind regarding feature…]]></description><link>https://gatsby-starter-blog-demo.netlify.com/machine-learning-feature-engineering</link><guid isPermaLink="false">https://gatsby-starter-blog-demo.netlify.com/machine-learning-feature-engineering</guid><content:encoded>&lt;h1&gt;Feature Engineering&lt;/h1&gt;
&lt;h2&gt;Identifying Important Features In Random Forests&lt;/h2&gt;
&lt;p&gt;NOTE:  there are two things to keep in mind regarding feature importance:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;While not technically required, scikit-learn requires that we break up nominal categorical features into multiple binary features. This has the effect of spreading the importance of that feature across all of the bninary features and can often makes each feature appear to be &lt;em&gt;umimportant&lt;/em&gt; even when the original nominal categorical feature is highly imprtant&lt;/li&gt;
&lt;li&gt;If two features are highly correlated then one feature will claim much of the importance, making the other feature appear to be far less important, which has implications for interpretation if not considerred.&lt;/li&gt;
&lt;/ul&gt;</content:encoded></item><item><title><![CDATA[No title]]></title><description><![CDATA[Introduction A diagram of AI in computer science Rule-based system VS Machine learning The logic required to make a decision is specific to…]]></description><link>https://gatsby-starter-blog-demo.netlify.com/machine-learning-intro</link><guid isPermaLink="false">https://gatsby-starter-blog-demo.netlify.com/machine-learning-intro</guid><content:encoded>&lt;h1&gt;Introduction&lt;/h1&gt;
&lt;h2&gt;A diagram of AI in computer science&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://github.com/MagicMike90/Notes/blob/master/Machine-Learning/ai_explaination.jpg&quot; alt=&quot;alt text&quot; title=&quot;A diagram of AI category1&quot;&gt;&lt;/p&gt;
&lt;h2&gt;Rule-based system VS Machine learning&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;The logic required to make a decision is specific to a single domain and task. Changing the task even slightly might require a rewrite of the whole system.&lt;/li&gt;
&lt;li&gt;Designing rules requires a deep understanding of how a decision should be made by a human expert.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Machine learning summarized in four categories.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Predictive learning: comprises two kinds of tasks where we aim to either predict a continuous valued phenomenon (like the future location of a celestial body), or distinguish between distinct kings of things (like different faces in an image)&lt;/li&gt;
&lt;li&gt;Feature design: A broad set of engineering and mathematical tools which are crucial to the successful performance of predictive learning models in practice.&lt;/li&gt;
&lt;li&gt;Function approximation: It is employed when we know too little abut a dataset to produce proper features ourselves (and therefore must learn them strictly from the data itself).&lt;/li&gt;
&lt;li&gt;Numerical optimization  powers the first three and is the engine that makes machine learning run in practice.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Cost function&lt;/h2&gt;
&lt;p&gt;One of the key ingredients of supervised machine learning algorithms is to define
an objective function that is to be optimized during the learning process. This
objective function is often a cost function that we want to minimize.&lt;/p&gt;
&lt;h2&gt;Predictive learning problems&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Regression:&lt;/li&gt;
&lt;li&gt;Classification: The key difference between the two is that instead of predicting a continuous-valued output (e.g., share price blood pressure, etc.), with classification what we aim at predicting takes on discrete values or classes.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Three types of machine learning&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Supervised learning (making predictions about the future):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;supervised&lt;/strong&gt; refers to a set of samples where the desired output signals (lables ) are already known.&lt;/li&gt;
&lt;li&gt;There are two sub categories:&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;classification&lt;/strong&gt;: the goal is to predict the categorical class labels of new instances based on the pas observations, which is a choice from a predfined list of possibilities.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;i.e. distinguish spam and non-spam email&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;regression&lt;/strong&gt;: for predicting continuous outcomes, given a number of &lt;em&gt;predictor&lt;/em&gt; ( explanatory) variables and a continuous response variable (outcome), and we try to find a relationship between those variables that allows us to predict an outcome.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;i.e. predict a relationship between the time spent studying for the test and the final scores&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;examples:&lt;/li&gt;
&lt;li&gt;Identifying the ZIP code from handwritten digits on an envelope.&lt;/li&gt;
&lt;li&gt;Determining whether or not a tumor is benign based on a medical image.&lt;/li&gt;
&lt;li&gt;Detecting fraudulent activity in credit card transactions&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;A easy way to distinguish between classifcation and regression tasks is to ask whether there is some kind of continuity in the output.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Unsupervised learning (Discovering hidden structures):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;In uservised learning, we know the right answer beforehand when we train our model, and in reinforcement learning, we define a measure of reward for particular actions by the agent. In unsupervised learning, however, we are dealling with unlabeled data or data of unkow structure.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;cluster&lt;/strong&gt;: is an exploratory data analysis technique that allows us to organize a pile of information into meaningful subgroups (&lt;em&gt;clusters&lt;/em&gt;) without having any prior knowledge of their group menmeberships.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;i.e.&lt;/em&gt; it allows marketers to discover customer groups based on their interests in order to develop distinct mareting programs&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;dimensionality reduction&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;It is a commonly used approach in feature preprocessing to remove noise from data, which can also degrade the predictive performance of certain algorithms, and compress the data onto a smaller dimensional subspace while retaining most of the relevant information. &lt;/li&gt;
&lt;li&gt;Examples:&lt;/li&gt;
&lt;li&gt;Identifying topics in a set of blog posts.&lt;/li&gt;
&lt;li&gt;Segmenting customers into groups with similar preferences.&lt;/li&gt;
&lt;li&gt;Detecting abnormal access patterns to a website.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;unsupervised algorithms are used offten in an explortory setting, when a data scientist wants to understand the data better, rather than as part of a larger automatic system. Another common application for unsupervised algorithms is as a preprocessing step for supervised algorithms.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;reinforcement learning (Solving interactive problems):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The goal is to develop a system (&lt;em&gt;agent&lt;/em&gt;) that improves its performance based on interactions with the &lt;em&gt;enviroment&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;i.e. chess engine&lt;/em&gt;, the agent decides upon a series of moves depending on the state of the board (the enviroment) and reward can be difned as &lt;em&gt;win&lt;/em&gt; or &lt;em&gt;lose&lt;/em&gt; at the end of the game&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Predictive modeling&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Preprocessing&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Feature extraction and scalling&lt;/li&gt;
&lt;li&gt;Feature selection&lt;/li&gt;
&lt;li&gt;Dimensionality reduction&lt;/li&gt;
&lt;li&gt;sampling&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Learning&lt;/li&gt;
&lt;li&gt;Evaluation&lt;/li&gt;
&lt;li&gt;Prediction&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Feature python libaries&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;NumPy&lt;/li&gt;
&lt;li&gt;SciPy&lt;/li&gt;
&lt;li&gt;scikit-learn&lt;/li&gt;
&lt;li&gt;pandas&lt;/li&gt;
&lt;li&gt;matplotlib&lt;/li&gt;
&lt;/ul&gt;</content:encoded></item><item><title><![CDATA[No title]]></title><description><![CDATA[Model evaluation and Hyperparameter tuning Holdout cross-validation A classic and popular approach for estimating the generalization…]]></description><link>https://gatsby-starter-blog-demo.netlify.com/machine-learning-model-evaluation-hyperparameter-tuning</link><guid isPermaLink="false">https://gatsby-starter-blog-demo.netlify.com/machine-learning-model-evaluation-hyperparameter-tuning</guid><content:encoded>&lt;h1&gt;Model evaluation and Hyperparameter tuning&lt;/h1&gt;
&lt;h2&gt;Holdout cross-validation&lt;/h2&gt;
&lt;p&gt;A classic and popular approach for estimating the generalization performance of machine learning models is holdout cross-validation.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Model selection&lt;/strong&gt;: tuning and comparing different paramenter settings to further improve the performance for making predictions on unsee data, it refers to a givent classifcation problem for which we want to select the optimal values of tunning parameters. (&lt;strong&gt;Hyperparameters&lt;/strong&gt;)&lt;/p&gt;
&lt;p&gt;A better way of using holdout method for modle selection is to separate the data into three parts: a traning set, a validation set, and a test set.&lt;/p&gt;
&lt;p&gt;The advantage of having a test set that the model hasn’t seen before during the training and model selection steps is that we can objtain a less biased estimate of its ability to generalize to new data.&lt;/p&gt;
&lt;p&gt;A disadvantage of the holdout method is that the preformance estimate is sensitive to how we partition the training set into the training and validation subsets&lt;/p&gt;
&lt;h2&gt;K-fold cross-validation&lt;/h2&gt;
&lt;p&gt;Randomly split the training dataset into k folds without replacement, wheere k - 1 folds are used for the model training and on fold is use for testing. This procedure is repeated k times so that we obtain k models and performance estimates.&lt;/p&gt;
&lt;p&gt;Random sampling without replacement: 2, 1, 3, 4, 0
Random sampling with replacement: 1, 3, 3, 4, 1&lt;/p&gt;
&lt;p&gt;Benefits of cross validation:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;each example will be in the test set exactly once&lt;/li&gt;
&lt;li&gt;each example is in one of the folds, and each fold is the test set once&lt;/li&gt;
&lt;li&gt;having multiple splits of data provides some information about how sensitive our model is to the selection of the traning dataset.&lt;/li&gt;
&lt;li&gt;it is more effectively than train&lt;em&gt;test&lt;/em&gt;split&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Disadvantage:
it increase computational cost, since it trains k models instead of a single model, cross validation will be roughly k tims slower than doing a single split of data.&lt;/p&gt;
&lt;h2&gt;Debugging algorithms with learning and validation curves&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Diagnosing bias and variance problems with learning curves&lt;/li&gt;
&lt;li&gt;Addressing overfitting and underfitting with validation curves&lt;/li&gt;
&lt;li&gt;Fine-tuning machine learning models via grid search&lt;/li&gt;
&lt;li&gt;Algorithm selection with nested cross-validation&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Looking at different performance evaluation metrics&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;precision&lt;/li&gt;
&lt;li&gt;recall&lt;/li&gt;
&lt;li&gt;F1-score&lt;/li&gt;
&lt;li&gt;Receiver operator charateristic (ROC): this graphs are useful tools for selecting models for classification based on their performance with respect to the false positive and ture positive rates, which are computed by shifting the decision threshold of the classifer.&lt;/li&gt;
&lt;li&gt;Area under the cureve (AUC) can be computed based on ROC curve to charaterize the performance of a classification model&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;</content:encoded></item><item><title><![CDATA[No title]]></title><description><![CDATA[Regression Analysis Datasets ( https://archive.ics.uci.edu/ml/datasets/Housing ) CRIM: This is the per capita crime rate by town ZN: This is…]]></description><link>https://gatsby-starter-blog-demo.netlify.com/machine-learning-regression-analysis</link><guid isPermaLink="false">https://gatsby-starter-blog-demo.netlify.com/machine-learning-regression-analysis</guid><content:encoded>&lt;h1&gt;Regression Analysis&lt;/h1&gt;
&lt;h2&gt;Datasets (&lt;a href=&quot;https://archive.ics.uci.edu/ml/datasets/Housing&quot;&gt;https://archive.ics.uci.edu/ml/datasets/Housing&lt;/a&gt;)&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;CRIM: This is the per capita crime rate by town&lt;/li&gt;
&lt;li&gt;ZN: This is the proportion of residential land zoned for lots larger than 25,000 sq.ft.&lt;/li&gt;
&lt;li&gt;INDUS: This is the proportion of non-retail business acres per town&lt;/li&gt;
&lt;li&gt;CHAS: This is the Charles River dummy variable (this is equal to 1 if tract bounds river; 0 otherwise)&lt;/li&gt;
&lt;li&gt;NOX: This is the nitric oxides concentration (parts per 10 million)&lt;/li&gt;
&lt;li&gt;RM: This is the average number of rooms per dwelling&lt;/li&gt;
&lt;li&gt;AGE: This is the proportion of owner-occupied units built prior to 1940&lt;/li&gt;
&lt;li&gt;DIS: This is the weighted distances to five Boston employment centers&lt;/li&gt;
&lt;li&gt;RAD: This is the index of accessibility to radial highways&lt;/li&gt;
&lt;li&gt;TAX: This is the full-value property-tax rate per $10,000&lt;/li&gt;
&lt;li&gt;PTRATIO: This is the pupil-teacher ratio by town&lt;/li&gt;
&lt;li&gt;B: This is calculated as 1000(Bk - 0.63)^2, where Bk is the proportion of people of African American descent by town&lt;/li&gt;
&lt;li&gt;LSTAT: This is the percentage lower status of the population&lt;/li&gt;
&lt;li&gt;MEDV: This is the median value of owner-occupied homes in $1000s&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;RANDom SAmple Consensus (RANSAC) - fitting a robust regression model&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Select a random number of samples to be inliers and fit the model&lt;/li&gt;
&lt;li&gt;Test all other data points against the fitted model and add those points that fall within a user-givern tolerance to the inliers&lt;/li&gt;
&lt;li&gt;Refit the mole using all inliers.&lt;/li&gt;
&lt;li&gt;Estimate the error of the fitted model versus the inliers.&lt;/li&gt;
&lt;li&gt;Terminate the algorithm if the performance meets a certain user-defined threshold or if a fixed number of iterations has been reached; go back to step 1 otherwise&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Regulation&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Redge Regression&lt;/li&gt;
&lt;li&gt;Least Absolute&lt;/li&gt;
&lt;li&gt;Shrinkage and Selection Operator (LASSO)&lt;/li&gt;
&lt;li&gt;Elastic Net&lt;/li&gt;
&lt;/ul&gt;</content:encoded></item><item><title><![CDATA[No title]]></title><description><![CDATA[Sentiment Analysis bag of words model: It allows us to represent text as numerical feature vectores Transforming words into feature vectors…]]></description><link>https://gatsby-starter-blog-demo.netlify.com/machine-learning-sentiment-analysis</link><guid isPermaLink="false">https://gatsby-starter-blog-demo.netlify.com/machine-learning-sentiment-analysis</guid><content:encoded>&lt;h1&gt;Sentiment Analysis&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;bag of words model: It allows us to represent text as numerical feature vectores&lt;/li&gt;
&lt;li&gt;Transforming words into feature vectors&lt;/li&gt;
&lt;li&gt;Assessing word relevancy via term frequency-inverse document frequency&lt;/li&gt;
&lt;li&gt;Cleaning text data&lt;/li&gt;
&lt;li&gt;Processing documents into tokens&lt;/li&gt;
&lt;li&gt;Training a logistic regression model for document classification&lt;/li&gt;
&lt;li&gt;Online algorithms and out-of-core learning for large datasets&lt;/li&gt;
&lt;/ul&gt;</content:encoded></item><item><title><![CDATA[No title]]></title><description><![CDATA[Scifit-learn Overfitting  means that the model captures the patterns in the training data well, but fails to generalize well to unseen data…]]></description><link>https://gatsby-starter-blog-demo.netlify.com/machine-learning-scikit-learn</link><guid isPermaLink="false">https://gatsby-starter-blog-demo.netlify.com/machine-learning-scikit-learn</guid><content:encoded>&lt;h1&gt;Scifit-learn&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Overfitting&lt;/strong&gt; means that the model captures the patterns in the training data well, but fails to generalize well to unseen data.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Training data: the slited data used to build machine learning model&lt;/li&gt;
&lt;li&gt;Test data: the reset of the data is used to assess how well the model words&lt;/li&gt;
&lt;li&gt;In scikit-learn, data is usually denoted with a capital X, while labels are denoted by a lowercase y. This is inspired by the standard formulation f(x) = y in mathematics, where x is the input to a function and y is the output.&lt;/li&gt;
&lt;li&gt;X (capital) represents two-dimensional array ( a matrix) and a lowercase y represents one-dimensioanl array (a vector)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Pair plot&lt;/h2&gt;
&lt;p&gt;It is difficult to plot datasets with more than three features, due to computer have only two dimentsions, which allows us to plot only two (or maybe three) features at a time.
Pair plot looks at all possible pairs of features&lt;/p&gt;
&lt;h2&gt;Decision Tree&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Advantages&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The resulting model can easily be visulized and understood by noexperts (at least for smaller trees),.&lt;/li&gt;
&lt;li&gt;The algorithms are completely invariant to scaling of the data.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Disadvantage&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Even it use pre-pruning, they tend to overfit and provide poor generalization performance&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Ensembles of Decision Tress&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Random Forests&lt;/h2&gt;
&lt;p&gt;Random forests for regression and classification are currently among the most widely used machine learning methods.
It requires more memory and are slower to train and to predict than linear models, so if time and memory are important in an application, it might make sense to use a linear model instead.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;n_estimators&lt;/strong&gt;: larger is always better.&lt;/p&gt;
&lt;h2&gt;Gradient Boosted Regression Trees&lt;/h2&gt;
&lt;p&gt;Gradient boosted trees are frequently the winning entries in machine learning competitions, and are widely used in industry. They are generally a bit more sensitive to parameter settings than random forests, but can provide better accuracy if the parameters are set correctly.&lt;/p&gt;
&lt;h2&gt;Kernelized Support Vector Machines&lt;/h2&gt;
&lt;h2&gt;Neural Networks ( Deep Learning)&lt;/h2&gt;
&lt;p&gt;Adanvatage:
They are able to capture information contained in large amounts of data and build incredibly complex models. Given enough computation time, data, and careful tuning of the parameters, neural networks often beat other machine learning algorithms (for classifcation and regression tasks)&lt;/p&gt;
&lt;p&gt;Disadavantage
Take a long time to train.&lt;/p&gt;</content:encoded></item><item><title><![CDATA[No title]]></title><description><![CDATA[Training Algorithms Linear Algebra notes Numpy The advantage of using Numpy over classic Python for-loop structures is that its arithmetic…]]></description><link>https://gatsby-starter-blog-demo.netlify.com/machine-learning-training-algorithms</link><guid isPermaLink="false">https://gatsby-starter-blog-demo.netlify.com/machine-learning-training-algorithms</guid><content:encoded>&lt;h1&gt;Training Algorithms&lt;/h1&gt;
&lt;h2&gt;&lt;a href=&quot;http://www.cs.cmu.edu/~zkolter/course/linalg/linalg_notes.pdf&quot;&gt;Linear Algebra notes&lt;/a&gt;&lt;/h2&gt;
&lt;h2&gt;Numpy&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;The advantage of using Numpy over classic Python for-loop structures is that its arithmetic operations are vectorized, imporve the performance of operations by making better use of &lt;strong&gt;Single Instruction, Multiple Data (SIMD)&lt;/strong&gt; of moden CPU architecures.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;methods&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;dot()&lt;/strong&gt;:dot product of two pioints&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;zip()&lt;/strong&gt;:The zip() function take iterables (can be zero or more), makes iterator that aggregates elements based on the iterables passed, and returns an iterator of tuples.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;where&lt;/strong&gt;(condition[, x, y]): Return elements, either from x or y, depending on condition.i.e. np.where(y == ‘Iris-setosa’, -1, 1), where value equals ‘Iris-setosa’ will change to be -1.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Pandas&lt;/h2&gt;
&lt;p&gt;methods&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;read_csv()&lt;/strong&gt;: read csv file , return &lt;em&gt;DataFrame&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;tail()&lt;/strong&gt;: get last n line of DataFrame&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;iloc(array, index)&lt;/strong&gt;: get numer of rows of column index&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Disadvantage of perceptron&lt;/h2&gt;
&lt;p&gt;its biggest disadvantage is that it never converges if the classes are not perfectly linearly separable.&lt;/p&gt;
&lt;h2&gt;The curse of dimensionality&lt;/h2&gt;
&lt;p&gt;The curse of dimensionality describes the phenomenon where the feature
space becomes increasingly sparse for an increasing number
of dimensions of a fixed-size training dataset&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Regularization&lt;/em&gt; is not applicable such as decision trees and KNN, we can use feature selection and dimensionality reduction techniques to help us avoid the curse of dimensionality&lt;/p&gt;</content:encoded></item><item><title><![CDATA[No title]]></title><description><![CDATA[Summary of machine learning Common used machine learning algorithm Listed in order of increasing complexity: Logiistic regressiong K-nearest…]]></description><link>https://gatsby-starter-blog-demo.netlify.com/machine-learning-summary</link><guid isPermaLink="false">https://gatsby-starter-blog-demo.netlify.com/machine-learning-summary</guid><content:encoded>&lt;h1&gt;Summary of machine learning&lt;/h1&gt;
&lt;h2&gt;Common used machine learning algorithm&lt;/h2&gt;
&lt;p&gt;Listed in order of increasing complexity:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Logiistic regressiong&lt;/li&gt;
&lt;li&gt;K-nearest neighbors - Number of nearest neighbors to average&lt;/li&gt;
&lt;li&gt;Decision trees - Splitting criterion, max depth or tree, minimum saples needed to make a split&lt;/li&gt;
&lt;li&gt;Kernel SVM - Kernel type, kernel coefficient, penalty parameter&lt;/li&gt;
&lt;li&gt;Random forest - Number of trees, number of features to split in each node, splitting criterion, minimum saples needed to make a split&lt;/li&gt;
&lt;li&gt;Boosting - Number of trees learning rate, max depth of tree, split in each node, splitting criterion, minimun samples needed to make a split&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;General procesdure&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Project Scoping / Data Collection&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Inspect &amp;#x26; Explore&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Data preprocessing&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;formating, cleaning and sampling&lt;/li&gt;
&lt;li&gt;Data Transformation:&lt;/li&gt;
&lt;li&gt;Scalling&lt;/li&gt;
&lt;li&gt;Label coding&lt;/li&gt;
&lt;li&gt;One hot encoding for categorical feature&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Feature engineering&lt;/strong&gt; :It is the process of transforming raw data into features that better represent the underlying problem to the predictive models, resulting in improved model accuracy on unseen data&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Indicator Variables&lt;/li&gt;
&lt;li&gt;Indicator variable from thresholds&lt;/li&gt;
&lt;li&gt;Indicator variable from multiple features&lt;/li&gt;
&lt;li&gt;Indicator variable for special events&lt;/li&gt;
&lt;li&gt;Indicator variable for groups of classes&lt;/li&gt;
&lt;li&gt;Interaction Features&lt;/li&gt;
&lt;li&gt;Sum of two features&lt;/li&gt;
&lt;li&gt;Difference between two features&lt;/li&gt;
&lt;li&gt;Product of two features&lt;/li&gt;
&lt;li&gt;Quotient of two features&lt;/li&gt;
&lt;li&gt;Feature Representation&lt;/li&gt;
&lt;li&gt;Date and time features&lt;/li&gt;
&lt;li&gt;Numeric to categorical mappings&lt;/li&gt;
&lt;li&gt;Grouping sparse classes&lt;/li&gt;
&lt;li&gt;Creating dummy variables&lt;/li&gt;
&lt;li&gt;External Data&lt;/li&gt;
&lt;li&gt;Time series data&lt;/li&gt;
&lt;li&gt;External API’s&lt;/li&gt;
&lt;li&gt;Geocoding&lt;/li&gt;
&lt;li&gt;Other sources of the same data&lt;/li&gt;
&lt;li&gt;Error Analysis (Post-Modeling)&lt;/li&gt;
&lt;li&gt;Start with larger errors&lt;/li&gt;
&lt;li&gt;Segment by classes&lt;/li&gt;
&lt;li&gt;Unsupervised clustering&lt;/li&gt;
&lt;li&gt;Ask colleagues or domain experts&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Feature selection&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;It is a process where you automatically select those features in your data that contribute most to the prediction variable or output in which you are interested&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Dimensionality reduction&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;PCA&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Split train and test data set&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Train data&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Model evaluation and hyperparameter tuning&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Save and deploy model&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Reference&lt;/h2&gt;
&lt;p&gt;Books:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Introduction to Machine Learning with Python&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;review: get general ideas of how machine learning works&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Real-World Machine Learning&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;review: books follows general procedure to implement a machine learning model&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Python Machine Learning&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;review: it is a good book to advance machine learning knowledge with scikit-learn&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Pythoe Machine Learning Blueprints&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;review: a good book to build a full stack machine learning system with serveral examples&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Online courses:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Coursera - Machine Learning by Stanford University&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;review: A free open class designed by Standford University, this course teaches machine learning knowledge from basis to advance.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;</content:encoded></item><item><title><![CDATA[No title]]></title><description><![CDATA[Notes for Progressive Web App Case study - Facebook Facebook tried to make the web its primary platform, but due to many engineering…]]></description><link>https://gatsby-starter-blog-demo.netlify.com/pwa-readme</link><guid isPermaLink="false">https://gatsby-starter-blog-demo.netlify.com/pwa-readme</guid><content:encoded>&lt;h1&gt;Notes for Progressive Web App&lt;/h1&gt;
&lt;h2&gt;Case study - Facebook&lt;/h2&gt;
&lt;p&gt;Facebook tried to make the web its primary platform, but due to many engineering mistakes and browser/hardware limitations, they failed. At that point, they switched to native apps as a primary focus and have since created a very large, walled off community of data and interactions.&lt;/p&gt;</content:encoded></item><item><title><![CDATA[React Notes!]]></title><description><![CDATA[React Notes Communicate Child to Parent Since there is no way to communicate between siblings (only
parent to child and vice versa), keeping…]]></description><link>https://gatsby-starter-blog-demo.netlify.com/react</link><guid isPermaLink="false">https://gatsby-starter-blog-demo.netlify.com/react</guid><pubDate>Tue, 30 Jul 2019 00:00:00 GMT</pubDate><content:encoded>&lt;h1&gt;React Notes&lt;/h1&gt;
&lt;h2&gt;Communicate Child to Parent&lt;/h2&gt;
&lt;p&gt;Since there is no way to communicate between siblings (only
parent to child and vice versa), keeping the state at the root
of the hierarchy is the best strategy.&lt;/p&gt;
&lt;h2&gt;Spread Operator&lt;/h2&gt;
&lt;p&gt;“spread” operator to pass the whole props object.&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;jsx&quot;&gt;&lt;pre class=&quot;language-jsx&quot;&gt;&lt;code class=&quot;language-jsx&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;function&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;App1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;token keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;token tag&quot;&gt;&lt;span class=&quot;token tag&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;&amp;lt;&lt;/span&gt;Greeting&lt;/span&gt; &lt;span class=&quot;token attr-name&quot;&gt;firstName&lt;/span&gt;&lt;span class=&quot;token attr-value&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;&quot;&lt;/span&gt;Ben&lt;span class=&quot;token punctuation&quot;&gt;&quot;&lt;/span&gt;&lt;/span&gt; &lt;span class=&quot;token attr-name&quot;&gt;lastName&lt;/span&gt;&lt;span class=&quot;token attr-value&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;&quot;&lt;/span&gt;Hector&lt;span class=&quot;token punctuation&quot;&gt;&quot;&lt;/span&gt;&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;/&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;token keyword&quot;&gt;function&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;App2&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;token keyword&quot;&gt;const&lt;/span&gt; props &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;firstName&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&apos;Ben&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; lastName&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&apos;Hector&apos;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;token keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;token tag&quot;&gt;&lt;span class=&quot;token tag&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;&amp;lt;&lt;/span&gt;Greeting&lt;/span&gt; &lt;span class=&quot;token spread&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;...&lt;/span&gt;&lt;span class=&quot;token attr-value&quot;&gt;props&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;/&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;Object rest spread (Redux example)&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;http://redux.js.org/docs/recipes/UsingObjectSpreadOperator.html&quot;&gt;http://redux.js.org/docs/recipes/UsingObjectSpreadOperator.html&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Required module as default&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Create a index.js module&lt;/li&gt;
&lt;li&gt;improt A from ‘./folder_name’&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;React Router&lt;/h2&gt;
&lt;p&gt;&lt;code class=&quot;language-text&quot;&gt;withRouter&lt;/code&gt; will cause rerender if enable it in &lt;code class=&quot;language-text&quot;&gt;Route&lt;/code&gt;, it has bo be used when export component.&lt;/p&gt;
&lt;h2&gt;Fragment&lt;/h2&gt;
&lt;p&gt;A common pattern in React is for a component to return multiple elements. Fragments let you group a list of children without adding extra nodes to the DOM.&lt;/p&gt;
&lt;h2&gt;Using the state&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;We should always keep in mind that only the minimal amount of data needed should be put into the state&lt;/li&gt;
&lt;li&gt;We should add to the state only the values that we want to update when an event happens, and for which we want to make the component re-render.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Should component update&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Dont’ duplicate data from props in state, calculate what you can in render() method&lt;/li&gt;
&lt;li&gt;Don’t keep something in the state if you don’t use it for rendering, For example, API subscriptions are better off as custom private fields or variables in external modules.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Container and Presentational pattern&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;Container components&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;They are more concerned about the behavior&lt;/li&gt;
&lt;li&gt;They render their presentational components&lt;/li&gt;
&lt;li&gt;They make API calls and manipulate data&lt;/li&gt;
&lt;li&gt;They define event handlers&lt;/li&gt;
&lt;li&gt;They are written as classes&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;Presentational components`&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;They are more concerned with the visual representation&lt;/li&gt;
&lt;li&gt;They render the HTML markup (or other components)&lt;/li&gt;
&lt;li&gt;They receive data from the parents in the form of props&lt;/li&gt;
&lt;li&gt;They are often written as stateless functional components&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Function as Child&lt;/h2&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;javascript&quot;&gt;&lt;pre class=&quot;language-javascript&quot;&gt;&lt;code class=&quot;language-javascript&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;token function-variable function&quot;&gt;FunctionAsChild&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt; children &lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;=&gt;&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;children&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;

FunctionAsChild&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;propTypes &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;
  children&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt; React&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;PropTypes&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;func&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;isRequired
&lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;Uncontrolled Components&lt;/h2&gt;
&lt;p&gt;where we do not set the value of the input field, but we let the component manage its internal state.&lt;/p&gt;
&lt;h2&gt;Controlled Components&lt;/h2&gt;
&lt;p&gt;We have full control over the value of the fields&lt;/p&gt;
&lt;h2&gt;Event&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;Synthetic Event is an object that wraps the original event object provided by the browser, and it has the same properties, no matter the browser where it is created.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;event bubbling&lt;/strong&gt;: What it does instead is attach a single event handler to the root element, which listens to all the events,&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;single global handler&lt;/strong&gt;: When an event we are interested in is fired by the browser, React calls the handler on the specific components on its behalf.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Server side rendering&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;SEO :One of the main reasons we may want to render our applications on the server-side is Search Engine Optimization (SEO).&lt;/li&gt;
&lt;li&gt;A common code base: We do not have many options on the client: our applications have to be written in JavaScript. There are some languages that can be converted into JavaScript at build time, but the concept does not change.&lt;/li&gt;
&lt;li&gt;Better performance:we all love client-side applications, because they are fast and responsive, but there is a problem: the bundle has to be loaded and run before users can take any action on the application.&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;SSR or not&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;If your page is non-interactive don’t render it in the browser (Only render the page to HTML on the server.) (Not only is computational time saved by skipping rendering to the DOM but also load time is saved by skipping loading JavaScript code.)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If your page is non-interactive and doesn’t change on every request, then render it on the server at build-time.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The SSR should be enabled on when strictly needed. For example, if you need SEO or if you need to customize the social sharing information, you should start thinking about it.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If you realize that your application takes a lot of time to fully load and you have already done all the optimization (see the following chapter for more about this topic), you can consider using server-side rendering to offer a better experience to your users and improve the perceived speed.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Optimization&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Webpack UglifyJsPlugin&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Should component update&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;PurComponent&lt;/strong&gt; always re-render if the state or props reference a new object. This implies that if we do not want to lose the benefits of &lt;code class=&quot;language-text&quot;&gt;PureComponent&lt;/code&gt;, we should avoid such structures:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;javascript&quot;&gt;&lt;pre class=&quot;language-javascript&quot;&gt;&lt;code class=&quot;language-javascript&quot;&gt;&lt;span class=&quot;token operator&quot;&gt;&amp;lt;&lt;/span&gt;Entity values&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;token keyword&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;props&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;values &lt;span class=&quot;token operator&quot;&gt;||&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;It is important to remember, that &lt;code class=&quot;language-text&quot;&gt;PureComponent&lt;/code&gt; skips the re-render operation not only for component itself, but also for all its children, so the &lt;code class=&quot;language-text&quot;&gt;best use case&lt;/code&gt; for &lt;code class=&quot;language-text&quot;&gt;PureComponent&lt;/code&gt; are presentational components which have no child components and no dependencies on the global state in the application.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Stateless functional components&lt;/strong&gt;: Another concept that is sometimes counter-intuitive for beginners is the fact that stateless components do not give us any benefits regarding performance.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Testing&lt;/h2&gt;
&lt;p&gt;There are generally two ways of testing React components, by:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Shallow rendering&lt;/li&gt;
&lt;li&gt;Mounting the components into a detached DOM&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Before starting, it is important to have a clear idea about what we want to test and why.
The following list represents more or less all the variations and functionalities of the component that are worth testing:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The state is initialized with the value coming from the props&lt;/li&gt;
&lt;li&gt;The placeholder prop is correctly used in the element&lt;/li&gt;
&lt;li&gt;The right class names are applied following the conditional logic&lt;/li&gt;
&lt;li&gt;The state is updated whenever the value of the field changes&lt;/li&gt;
&lt;li&gt;The onSave callback is fired according to the different states and conditions&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;code class=&quot;language-text&quot;&gt;Snapshot Testing&lt;/code&gt;: Snapshots are pictures of the component with some props at a given point in time. Every time we run the tests, Jest creates new pictures and it compares them with the previous ones to check if something has changed, and It shows us what’s changed in the current snapshot.&lt;/p&gt;
&lt;p&gt;&lt;code class=&quot;language-text&quot;&gt;Test coverage&lt;/code&gt;: in some scenarios it is useful to get some measurement of the coverage and keep track of the numbers. In big projects with many different modules, doing so makes it easy to spot files that have not been adequately tested or that have not been tested at all.&lt;/p&gt;
&lt;h3&gt;Common testing solutions&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Testing Higher-Order Components&lt;/li&gt;
&lt;li&gt;The Page Object pattern&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Error handling with React&lt;/h3&gt;
&lt;p&gt;The best thing we can do when problems happen in our applications is:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Notify the users and help them understand what happened and what they should do&lt;/li&gt;
&lt;li&gt;Collect all useful information about the error and the state of the application in order to reproduce it and fix bugs quickly&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Avoid Anti-pattern&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Map data key&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The key has to be unique and stable, identifying one, and only one, item&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;use the value of the item if we expect it not to be repeated within the list, or create a unique identifier.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Spreading props on DOM elements&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;create a prop called domProps that we can spread safely to the component because we are explicitly saying that it contains valid DOM properties&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;HOC&lt;/h2&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;javascript&quot;&gt;&lt;pre class=&quot;language-javascript&quot;&gt;&lt;code class=&quot;language-javascript&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;import&lt;/span&gt; React &lt;span class=&quot;token keyword&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&quot;react&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;token comment&quot;&gt;// We receive a component constructor as an argument&lt;/span&gt;
&lt;span class=&quot;token keyword&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;token function-variable function&quot;&gt;makeRed&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; Component &lt;span class=&quot;token operator&quot;&gt;=&gt;&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;token comment&quot;&gt;// We make a new component constructor that takes props, just as any component&lt;/span&gt;
  &lt;span class=&quot;token keyword&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;token function-variable function&quot;&gt;wrappedComponent&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; props &lt;span class=&quot;token operator&quot;&gt;=&gt;&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;token comment&quot;&gt;// This new component returns the original component, but with the style applied&lt;/span&gt;
    &lt;span class=&quot;token keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;
      &lt;span class=&quot;token comment&quot;&gt;// But we also use the ES6 spread operator to apply the regular props passed in.&lt;/span&gt;
      &lt;span class=&quot;token comment&quot;&gt;// The spread operator applies props like the text in &amp;lt;RedButton text=&quot;hello&quot; /&gt;&lt;/span&gt;
      &lt;span class=&quot;token comment&quot;&gt;// to our new component&lt;/span&gt;
      &lt;span class=&quot;token comment&quot;&gt;// It will &quot;spread&quot; any and all props across our component&lt;/span&gt;
      &lt;span class=&quot;token operator&quot;&gt;&amp;lt;&lt;/span&gt;Component
        style&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt; backgroundColor&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&quot;red&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; color&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&quot;white&quot;&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;...&lt;/span&gt;props&lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;
      &lt;span class=&quot;token operator&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;&gt;&lt;/span&gt;
    &lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;token comment&quot;&gt;// We return the new constructor, so it can be called as &amp;lt;RedButton /&gt; or &amp;lt;RedAlertBox /&gt;&lt;/span&gt;
  &lt;span class=&quot;token keyword&quot;&gt;return&lt;/span&gt; wrappedComponent&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;token keyword&quot;&gt;export&lt;/span&gt; &lt;span class=&quot;token keyword&quot;&gt;default&lt;/span&gt; makeRed&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</content:encoded></item><item><title><![CDATA[Microservice Architecture Notes!]]></title><description><![CDATA[Microservice notes Domain-drive design It is very important to note that OOP is not only inheritance, interfaces, or anything else of the…]]></description><link>https://gatsby-starter-blog-demo.netlify.com/architecture-microservice</link><guid isPermaLink="false">https://gatsby-starter-blog-demo.netlify.com/architecture-microservice</guid><pubDate>Tue, 30 Jul 2019 00:00:00 GMT</pubDate><content:encoded>&lt;h1&gt;Microservice notes&lt;/h1&gt;
&lt;h2&gt;Domain-drive design&lt;/h2&gt;
&lt;p&gt;It is very important to note that OOP is not only inheritance, interfaces, or anything else of the type. OOP’s main ideas are as follows:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Code alignment with the business&lt;/li&gt;
&lt;li&gt;Favoring of reuse&lt;/li&gt;
&lt;li&gt;Minimal coupling&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;three are more prominent for efficient microservices:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Context maps: These are the communication paths between microservices with appropriate interactions between microservices teams. After the analysis of the areas are already defined, the team can choose to be dependent on another team for domain language.&lt;/li&gt;
&lt;li&gt;Anti-corruption layer (ACL): This is the function that translates foreign concepts for an internal model to provide loose coupling between the domains.&lt;/li&gt;
&lt;li&gt;Interchange context: This provides an environment for both teams and discusses the meaning of each foreign term and translates the languages of microservices.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Independent deploy, update, scale and replace&lt;/h2&gt;
&lt;h3&gt;Update&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Never share libraries between microservices&lt;/li&gt;
&lt;li&gt;Strong delimitation of microservice domains&lt;/li&gt;
&lt;li&gt;Establish a client-server relationship between microservices&lt;/li&gt;
&lt;li&gt;Deploy in separate containers&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Scale&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;The Scale Cube&lt;/strong&gt;: 3 axis&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;x-axis: horizontal decomposition: with the same application server replicated n times in full and in a balanced order of 1/n.&lt;/li&gt;
&lt;li&gt;y-axis: functional decomposition: a verb or route is used by the balancer to identify where to go with the request.&lt;/li&gt;
&lt;li&gt;z-axis: data partitioning: is very similar to the x-axis when it comes to scalability structure, as it distributes exactly the same code on each server. The big difference is that each server responds to a specific subset of data&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Communication&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;One-to-One&lt;/th&gt;
&lt;th align=&quot;right&quot;&gt;One-to-Many&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Synchronous&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;Request/response&lt;/td&gt;
&lt;td align=&quot;right&quot;&gt;-&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Asynchronous&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;Notification&lt;/td&gt;
&lt;td align=&quot;right&quot;&gt;publish/subsribe&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;Request/ async response&lt;/td&gt;
&lt;td align=&quot;right&quot;&gt;publish/async responses&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3&gt;Synchronous&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;HTTP&lt;/li&gt;
&lt;li&gt;TCP&lt;/li&gt;
&lt;li&gt;WebSockets&lt;/li&gt;
&lt;li&gt;Sockets&lt;/li&gt;
&lt;li&gt;RPC&lt;/li&gt;
&lt;li&gt;SOAP&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Asynchronous&lt;/h3&gt;
&lt;p&gt;For this approach, the message broker is just perfect. Some software applications appear a good choice for message brokers, such as RabbitMQ, ActiveMQ, ZeroMQ, Kafka, and Redis. Each of these options has its own peculiarities, some are faster, others are more resilient. Again, the business setting is going to determine which technology is used.&lt;/p&gt;
&lt;h3&gt;Mobile vs web endpoints&lt;/h3&gt;
&lt;p&gt;Problems such as speed and weight information in the web world are not very common; we cannot say the same for the mobile world.&lt;/p&gt;
&lt;h3&gt;Caching at the client level&lt;/h3&gt;
&lt;p&gt;request only passes to be processed on the backend, if really necessary. In other words, it tries to block direct access to the backend to requests that have already been implemented in the recent past.&lt;/p&gt;
&lt;h3&gt;Throttling for your client&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Number of requests per minute from the same client&lt;/li&gt;
&lt;li&gt;Number of requests per second from the same client&lt;/li&gt;
&lt;li&gt;Number of requests per minute from the same client for similar information&lt;/li&gt;
&lt;li&gt;Number of requests per second for the same client for the same information&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Identification of an anemic domain&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;The microservice cannot perform the tasks itself with only the data received&lt;/li&gt;
&lt;li&gt;The microservice needs to fetch data in more than one endpoint to perform a task&lt;/li&gt;
&lt;li&gt;The microservice does not have a self-sufficient entity model&lt;/li&gt;
&lt;li&gt;The microservice waits for the completion of a task in another microservice to follow up what you need to do&lt;/li&gt;
&lt;li&gt;The microservice needs to share resources with other external microservices; these resources can be cached to the sample database&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If the microservice being developed is one of those items, then it can be a weak area. If a microservice has two or more characteristics of those listed, then it is definitely an anemic domain.&lt;/p&gt;
&lt;p&gt;Anemic domains are very harmful to the microservices ecosystem, because they have a tendency to be multiplied in order to correct the technical debt generated by the deficiency in the composition of their respective domains.&lt;/p&gt;
&lt;h3&gt;Fat domain - AAA (Authentication, Authorization, and Accounting&lt;/h3&gt;
&lt;p&gt;The division of this fat domain can be held in two parts; the first part is AAAService and the second is UserService. Another approach is the AAA responsibility for a gateway API. The functional scalability and features of implementation with these separate domains is much more interesting for the growth of the product as a whol&lt;/p&gt;
&lt;h2&gt;Things to consider&lt;/h2&gt;
&lt;p&gt;Cost and scability:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Programming languages&lt;/li&gt;
&lt;li&gt;Microservices frameworks&lt;/li&gt;
&lt;li&gt;Binary communication&lt;/li&gt;
&lt;li&gt;Message broker&lt;/li&gt;
&lt;li&gt;Caching tools&lt;/li&gt;
&lt;li&gt;Fail alert tools&lt;/li&gt;
&lt;li&gt;Locale proof performance&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Death Start&lt;/h2&gt;
&lt;p&gt;The Death Star is an anti-pattern where there is communication between the recursion microservices, and making progress becomes extremely complicated or expensive for a product.&lt;/p&gt;
&lt;h2&gt;Message broker - Async communication between services&lt;/h2&gt;
&lt;p&gt;why not use this messaging for all types of communication between microservices?&lt;/p&gt;
&lt;p&gt;The answer to this question is quite simple. A message bus is a physical component within the stack of microservices. It needs to be scaled just like any other physical component-based data storage and cache. This means that with a high-volume message, the synchronous mode of communication could be committed to an unwanted delay in the responses of the processes.&lt;/p&gt;
&lt;h3&gt;Tools&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;ActiveMQ&lt;/li&gt;
&lt;li&gt;RabbitMQ&lt;/li&gt;
&lt;li&gt;Kafka&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;Caching tools&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Memcached
classic process of using cache, Memcached is simple and practical to use. The performance of Memcached is fully linked to the use of memory. If Memcached uses the disc to register any data, the performance is seriously compromised; moreover, Memcached does not have any record of disk capacity and always depends on third-party tools for this.&lt;/li&gt;
&lt;li&gt;Redis&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;Fail alert tools&lt;/h4&gt;
&lt;p&gt;four major points of failure when it comes to microservices&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Performance - New Relic and Datadog&lt;/li&gt;
&lt;li&gt;Build - Jenkins, Travis&lt;/li&gt;
&lt;li&gt;Components - Nagios and Zabbix are also very useful for making aid work to health check endpoints.&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Implementation failures - Sentry&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;See the impact of new deployments in real time&lt;/li&gt;
&lt;li&gt;Provide support to specific users interrupted by an error&lt;/li&gt;
&lt;li&gt;Detect and thwart fraud as it’s attempted: unusual amounts of failures on purchases, authentication, and other critical areas&lt;/li&gt;
&lt;li&gt;External integrations&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Locale proof performance&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Apache Benchmark&lt;/li&gt;
&lt;li&gt;WRK&lt;/li&gt;
&lt;li&gt;Locust&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Internal Patterns&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Developing the structure&lt;/li&gt;
&lt;li&gt;Caching strategies&lt;/li&gt;
&lt;li&gt;CQRS – query strategy&lt;/li&gt;
&lt;li&gt;Event sourcing – data integrity&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;CQRS(Command Query Responsibility Segregation)&lt;/h2&gt;
&lt;p&gt;As the name implies, it is about separating the responsibility of writing and reading of data. CQRS is a code pattern and not an architectural pattern.&lt;/p&gt;
&lt;p&gt;&lt;code class=&quot;language-text&quot;&gt;Will just scaling the application servers solve all our problems?&lt;/code&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Deadlocks, timeouts, and slowness mean that your database may be in too much demand.&lt;/li&gt;
&lt;li&gt;Complex queries can be performed to obtain database data. ORMs can add even more complexity to the data filtering process by mapping entities and filtering data by using joins in different tables.&lt;/li&gt;
&lt;li&gt;Content obsolescence could be true&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The CQRS teaches us the division of responsibility for writing and reading data, both conceptual and using different physical storages. This means that there will be separate means for recording and retrieving data from the databases. Queries are done synchronously in a separate denormalized database, and writes asynchronously to a normalized database. Caching first is still a type of CQRS implementation at the conceptual level.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Command&lt;/strong&gt; will be responsible for modifying the state of the data in the application, &lt;strong&gt;Query&lt;/strong&gt; is the operation responsible for retrieving information from the database.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Synchronization&lt;/strong&gt;: The following are some strategies to keep the foundations of reading and recording synchronized, and it is necessary to choose the one that best meets your scenario:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Automatic updating: All changes in the state of a given recording database raise a synchronous process to update on the bench&lt;/li&gt;
&lt;li&gt;Update possible: All state changes of a given recording database trigger an asynchronous process to update the reading bank, offering an eventual data consistency&lt;/li&gt;
&lt;li&gt;Controlled update: A regular process and schedule is raised to synchronize the databases&lt;/li&gt;
&lt;li&gt;Update on demand: Every query checks the consistency of the read base compared to the recording, and forces an update if it is out of date&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Any update is one of the most used strategies, because it assumes that any given displayed data may already be out of date, so it is not necessary to impose a synchronous update process.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Queueing&lt;/strong&gt;: Many CQRS implementations may require a message broker for the processing of commands and events.&lt;/p&gt;
&lt;h2&gt;Event sourcing – data integrity&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Each change in the current state of your database would be a new event in a stream that only allows inclusion.&lt;/li&gt;
&lt;li&gt;Each update on the table would generate a new line, the change of status&lt;/li&gt;
&lt;li&gt;uses the append only model for database records&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Aggregator Microservice Design Pattern&lt;/h2&gt;
&lt;p&gt;Best practices:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Segregated database: This allows us to better scale our application, especially in the data storage layer.&lt;/li&gt;
&lt;li&gt;Microservice encapsulation: This divides the microservices into two layers—Public Facing Services and Internal Services. Such a division allows for greater flexibility with respect to the signature microservices, as Internal Services can be modified more easily.&lt;/li&gt;
&lt;li&gt;Applied CQRS: With CQRS, unnecessary stress points on the application were removed.&lt;/li&gt;
&lt;li&gt;Applied event sourcing: With event sourcing, we are conducting a stream of information from a news article. This gives us a real vision of the history of each news article.&lt;/li&gt;
&lt;li&gt;Applied pattern very scalable: With a strong pattern and understanding of how to scale the aggregator pattern, we have a clear vision of how to avoid anti-patterns.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Pros:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Scalability of both the x-axis and z-axis&lt;/li&gt;
&lt;li&gt;Tunneling microservices&lt;/li&gt;
&lt;li&gt;Microservices signature flexibility to Internal Services&lt;/li&gt;
&lt;li&gt;Providing a single access point for microservices&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Cons:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Complexity to orchestrate data&lt;/li&gt;
&lt;li&gt;Bottleneck anti-pattern&lt;/li&gt;
&lt;li&gt;Latency in communication between microservices&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Proxy design pattern&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Dumb proxy - the only goal is to provide a single endpoint to facilitate the application clients and encapsulate direct access to the routes of microservices.&lt;/li&gt;
&lt;li&gt;Smart proxy - The most commonly seen task being executed by a Smart proxy is the content modification.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Pros:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Practical data consumption by the application clients&lt;/li&gt;
&lt;li&gt;Ease of implementation&lt;/li&gt;
&lt;li&gt;Possibility of good programming techniques at proxy level, such as caching&lt;/li&gt;
&lt;li&gt;Encapsulation of access to microservices&lt;/li&gt;
&lt;li&gt;Control and diversion of requests&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Cons:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Bottleneck&lt;/li&gt;
&lt;li&gt;Inappropriate change of response&lt;/li&gt;
&lt;li&gt;Obstruction in the identification of overload&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Chained Microservice Design pattern&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Big Ball of Mud Anti-patern&lt;/strong&gt;:developing microservices that we do not define well in the domains, which makes microservices dependent on one another to complete trivial tasks. This type of error generates a series of unnecessary calls between the microservices, creating complex problems of being corrected, such as latency and, in the worst cases, cyclic-deployed dependency.&lt;/p&gt;
&lt;p&gt;Main characteristics:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Poorly defined domain&lt;/strong&gt;: The domain is badly defined, forcing a direct connection with other microservices. Access points to the microservice do not require enough data to process a task, which forces the inference of data, searching in other microservices.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Mandatory direct communication&lt;/strong&gt;: When direct communication between microservices is mandatory for most tasks or for all tasks, there is a problem. This indicates that the microservice is anemic or that the application as a whole is poorly developed.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Deploy clustered&lt;/strong&gt;: When a microservice cannot be sent for production because it needs another microservice all together, or when the change of internal signatures of a microservice causes others to collapse, there is a Death Star anti-pattern issue. Creating business dependencies between microservices means that processes are not automated and fluid.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;Solution&lt;/em&gt;:
Correlation ID: A simple way to implement correlation ID using HTTP would be to send a UUID in the header of the requests and use this UUID as an identifier to write the logs.&lt;/p&gt;
&lt;h3&gt;Purest microservices&lt;/h3&gt;
&lt;p&gt;The microservices in your business design should be pure. This means that a microservice must be extremely small in its domain and fully capable of performing its function without outside interference from other microservices.&lt;/p&gt;
&lt;p&gt;Pros:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Practical implementation&lt;/li&gt;
&lt;li&gt;Dynamism for business&lt;/li&gt;
&lt;li&gt;Independent scalability&lt;/li&gt;
&lt;li&gt;Encapsulation of access to microservices&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Cons:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The possibility of latency points&lt;/li&gt;
&lt;li&gt;The difficulty in understanding data ownership&lt;/li&gt;
&lt;li&gt;The difficulty of debugging&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Branch Microservice Design Pattern&lt;/h2&gt;
&lt;p&gt;Rules:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The composition of the response using direct call chains cannot extend one direct call to another microservice&lt;/li&gt;
&lt;li&gt;If more values are required for the response, an aggregation logic is created that will trigger concurrent requests for as many chains as needed&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Internal communication within a microservice can be worked on in the following three ways:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Sequential: No concurrency or parallelism. This means that when we have to send messages from the commands to the microservices, the entire process will be a sequence. If you need to execute four commands to compose the data, all of them will be executed in a sequence.&lt;/li&gt;
&lt;li&gt;Threads: In this case, both POSIX threads (pthreads) and green threads can be used. Controlling threads is often not simple for developers, and if a thread fails, data orchestration could be compromised. However, it is the most practical way because there is no need for any external components of the programming language to be used for creating some level of competition or parallelism in the execution of the commands.&lt;/li&gt;
&lt;li&gt;Message Broker: The use of a transactional message broker for transmitting sensitive data within a microservice is quite usual. The disadvantage is the addition of a physical component within a microservice. However, the advantage is the ability to execute strategies that offer more resiliency in data transmission. The simple fact of working with transactions is already a great resource.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Pros:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The flexibility of implementation&lt;/li&gt;
&lt;li&gt;Independent scalability&lt;/li&gt;
&lt;li&gt;Encapsulation of access to microservices&lt;/li&gt;
&lt;li&gt;Compositional ability and orchestration&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Cons:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The possibility of latency points&lt;/li&gt;
&lt;li&gt;The difficulty in understanding data ownership&lt;/li&gt;
&lt;li&gt;The difficulty of debugging&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Asynchronous messaing design pattern&lt;/h2&gt;
&lt;p&gt;Pros:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Independent scalability&lt;/li&gt;
&lt;li&gt;Extreme scalability&lt;/li&gt;
&lt;li&gt;Lazy processing&lt;/li&gt;
&lt;li&gt;Encapsulation of accesses to microservices&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Cons:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Complexity in the monitoring of requisitions&lt;/li&gt;
&lt;li&gt;Complexity of the initial understanding of the pattern&lt;/li&gt;
&lt;li&gt;Difficulty of debugging&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;replese piplelines&lt;/h2&gt;
&lt;p&gt;Build -&gt; Unit Test -&gt; Integration Test -&gt; End-to-End test -&gt; realse&lt;/p&gt;
&lt;h2&gt;Monitoring a single service&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code class=&quot;language-text&quot;&gt;Active Monitoring&lt;/code&gt;is when the server that is to be monitored sends the status information to the monitoring tool&lt;/li&gt;
&lt;li&gt;&lt;code class=&quot;language-text&quot;&gt;Passive Monitoring&lt;/code&gt; is when the monitoring tool requests information about the state of the machine or application from the server&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Multiple service instances per host&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Pros&lt;/strong&gt;
One of the key benefits is that it uses resources efficiently. Multiple instances of the service share the server and its operating system. Another benefit of this pattern is the relatively rapid deployment of a microservice instance.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Cons&lt;/strong&gt;
A major disadvantage is that there is little to no isolation of instances of the service unless each service instance is a separate process. If the instances are not separated in different processes, an instance with errors could compromise the entire process, besides making the individual monitoring of instances impossible.&lt;/p&gt;
&lt;h2&gt;Service instance per host&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Service instance per VM: Each instance of a microservice is a VM, and the execution of this VM enables the microservice to work.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Pros: One of the main benefits of VMs is that each instance of microservice runs in a completely isolated manner, having fixed CPU and memory consumption, without competing for resource consumption with other microservices. Another great benefit of this pattern is the encapsulation of the technology used in the development of microservices.&lt;/li&gt;
&lt;li&gt;Cons: Each service instance has the overhead of a full VM, including the operating system. Another disadvantage of this approach is that deploying and booting a new version of a microservice is often slow because the cost of booting operating systems using VMs can be high.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Service instance per container: each microservice instance runs in a container unique to the instance.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Pros: They isolate their instances of microservices from one another. Containers are easily monitored. In addition, similar to the VMs, the containers encapsulate the technology used to implement microservices. Unlike the virtual machines, the containers are lighter. The container images are usually very fast to build and initialize.&lt;/li&gt;
&lt;li&gt;Cons: There are some disadvantages to using containers. Containers are not as secure as VMs because they share the host operating system kernel with each other.Another disadvantage of the containers is the complexity of the infrastructure if they are not using any cloud platform that offers interesting mechanisms to manipulate the containers.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;</content:encoded></item><item><title><![CDATA[Notes for Scrapy!]]></title><description><![CDATA[Scrapy notes Database choice If you plan to build some kind of search engine later on, Elasticsearch was a good choice If on the other hand…]]></description><link>https://gatsby-starter-blog-demo.netlify.com/python-scrapy</link><guid isPermaLink="false">https://gatsby-starter-blog-demo.netlify.com/python-scrapy</guid><pubDate>Fri, 26 Jul 2019 00:00:00 GMT</pubDate><content:encoded>&lt;h1&gt;Scrapy notes&lt;/h1&gt;
&lt;h2&gt;Database choice&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;If you plan to build some kind of search engine later on, Elasticsearch was a good choice&lt;/li&gt;
&lt;li&gt;If on the other hand you just want to store the data and do processing tasks on it later, Elasticsearch was a poor choice and you would be better off with Cassandra or another NoSQL database.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Important notes&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Python twisted&lt;/li&gt;
&lt;li&gt;Using MySQL instead of MongoDB due to some of the drawbacks that when using MongoDB as Database for data scraping.&lt;/li&gt;
&lt;li&gt;Using large pool of IP (proxy) to route requests&lt;/li&gt;
&lt;li&gt;Increasing request delay&lt;/li&gt;
&lt;li&gt;Reduce number of requests per second&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;A table that can help you decide what the best mechanism for a given problem is:&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;strong&gt;Problem&lt;/strong&gt;&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;&lt;strong&gt;Solution&lt;/strong&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;Something that is specific to the website that I’m crawling.&lt;/em&gt;&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;&lt;code class=&quot;language-text&quot;&gt;Modify your Spider.&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;Modifying or storing Items—domain-specific, may be reused across projects.&lt;/em&gt;&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;&lt;code class=&quot;language-text&quot;&gt;Write an Item Pipeline.&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;Modifying or dropping Requests/Responses—domain-specific,may be reused across projects&lt;/em&gt;&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;&lt;code class=&quot;language-text&quot;&gt;Write a spider middleware.&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;Executing Requests/Responses—generic, for example,to support some custom login scheme or a special way to handle cookies.&lt;/em&gt;&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;&lt;code class=&quot;language-text&quot;&gt;Write a downloader middleware.&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;em&gt;All other problems.&lt;/em&gt;&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;&lt;code class=&quot;language-text&quot;&gt;Write an extension.&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h1&gt;Performance&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Find the bottleneck&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;lantencies: t(download) = t(response) + t(overhead)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;t(job) = (N(request) * (t(response) + t(overhead))) / CONCURRENT_REQUESTS + t(start/stop)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Parameters control&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;t(overhead): more powerful server&lt;/li&gt;
&lt;li&gt;t(start/stop) : same as above&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Caculate the throughput&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;T = N/(t(job) - t(start/stop))&lt;/li&gt;
&lt;li&gt;By running a long job of N Requests, we can measure the job t aggregated time and then it’s straightforward to calculate T.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Case study:&lt;/h2&gt;
&lt;h3&gt;1. saturated CPU&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Solution&lt;/strong&gt;: I will assume that your code is, in general, efficient. You can get
aggregated concurrency larger than &lt;em&gt;CONCURRENT&lt;/em&gt;REQUESTS_ by running many Scrapy
crawlers on the same server. This will help you utilize more of the available cores
especially if other services or other threads from your pipelines don’t use them.
If you need even more concurrency, you can use multiple servers (see Chapter 11,
Distributed Crawling with Scrapyd and Real-Time Analytics), in which case you will
likely have more memory, network bandwidth, and hard disk throughput available
as well. Always double-check that CPU usage is your primary constraint.&lt;/p&gt;
&lt;h3&gt;2. blocking code&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Solution&lt;/strong&gt;: I will assume that you inherited the code base, and you have no intuition
on where the blocking code is. If the system can be functional without any pipelines,
then disable your pipelines and check whether the odd behavior persists. If yes, then
your blocking code is in your spider. If not, then enable pipelines one-by-one and
see when the problem starts. If the system can’t be functional without everything
running, then add some log messages on each pipeline stage (or interleave dummy
pipelines that print timestamps) in between your functional ones. By checking the
logs, you will easily detect where your system spends most of its time. If you want
a more long-term/reusable solution, you can trace your Requests using dummy
pipelines that add timestamps at each stage to the meta fields of Request. At the end,
hook to the item&lt;em&gt;scraped signal and log the timestamps. As soon as you find your
blocking code, convert it to Twisted/asynchronous or use Twisted’s thread pools. To
see the effects of this conversion, rerun the previous example while replacing SPEED&lt;/em&gt;
&lt;em&gt;PIPELINE&lt;/em&gt;BLOCKING&lt;em&gt;DELAY&lt;/em&gt; with &lt;em&gt;SPEED&lt;/em&gt;PIPELINE&lt;em&gt;ASYNC&lt;/em&gt;DELAY_. The change in
performance is stunning.&lt;/p&gt;
&lt;h3&gt;3. “garbage” on the downloader&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Solution&lt;/strong&gt;: We can solve this problem using treq instead of &lt;em&gt;crawler.engine.
download().&lt;/em&gt; You will note that this will skyrocket the scraper’s performance, which
might be bad news for your API infrastructure. I would start with a low number
of &lt;em&gt;CONCURRENT&lt;/em&gt;REQUESTS_ and increase gradually to make sure I don’t overload the
API servers.&lt;/p&gt;
&lt;h3&gt;4. overflow due to many or large responses&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Solution&lt;/strong&gt;: There isn’t much you can do for this problem with the existing infrastructure.
It would be nice to be able to clear the body of Response as soon as you don’t need it
anymore—likely after your spider, but doing so won’t reset Scraper’s counters at the
time of writing. All you can really do is try to reduce your pipeline’s processing time
effectively reducing the number of Responses in progress in the Scraper. You can
achieve this with traditional optimization: checking whether APIs or databases you
potentially interact with can support your scraper’s throughput, profiling the scraper,
moving functionality from your pipelines to batch/postprocessing systems, and
potentially using more powerful servers or distributed crawling.&lt;/p&gt;
&lt;h3&gt;5. overflow due to limited/excessive item concurrency&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Solution&lt;/strong&gt;: It’s very easy to detect both problematic symptoms of this case. If you
get very high CPU usage, it’s good to reduce the number of CONCURRENT&lt;em&gt;ITEMS. If
you hit the 5 MB Response limit, then your pipeline can’t follow your downloader’s
throughput and increasing CONCURRENT&lt;/em&gt;ITEMS might be able to quickly fix this. If it
doesn’t make any difference, then follow the advice in the previous section and ask
yourself twice if the rest of the system is able to support your Scraper’s throughput.&lt;/p&gt;
&lt;h3&gt;6. the downloader doesn’t have enough to do&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Solution&lt;/strong&gt;: If each index page has more than one next page link, we can utilize them
to accelerate our URL generation. If we can find pages that show more results (for
example, 50) per index page even better.&lt;/p&gt;
&lt;h2&gt;Troubleshooting flow&lt;/h2&gt;
&lt;p&gt;To summarize, Scrapy is designed to have the downloader as a bottleneck. Start with
a low value of CONCURRENT_REQUESTS and increase until just before you hit one of
the following limits:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;CPU usage &gt; 80-90%&lt;/li&gt;
&lt;li&gt;Source website latency increasing excessively&lt;/li&gt;
&lt;li&gt;Memory limit of 5 Mb of Responses in your scraper&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;At the same time also perform the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Keep at least a few Requests at all times in the scheduler’s queues (mqs/dqs)
to prevent the downloader’s URL starvation&lt;/li&gt;
&lt;li&gt;Never use any blocking code or CPU-intensive code&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;https://github.com/MagicMike90/Notes/blob/master/Python/Troubleshooting%20Scrapy&amp;#x27;s%20performance%20problems.png?raw=true&quot; alt=&quot;Troubleshooting Scrapy&amp;#x27;s performance problems&quot;&gt;&lt;/p&gt;
&lt;h2&gt;Scrapy Distibuted Crawling&lt;/h2&gt;
&lt;h2&gt;Crawl steps&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Inspect website structres&lt;/li&gt;
&lt;li&gt;Use different spiders in order to satify website current structures&lt;/li&gt;
&lt;li&gt;Using another application to schedule scrapy crawl&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Error&lt;/h2&gt;
&lt;p&gt;Offsite: Check &lt;code class=&quot;language-text&quot;&gt;allowed_domains&lt;/code&gt; if it matches the domain will be scraped&lt;/p&gt;
&lt;h2&gt;Setting&lt;/h2&gt;
&lt;p&gt;Using large pool of IP (proxy) to route requests
Increasing request delay
Reduce number of requests per second&lt;/p&gt;
&lt;h2&gt;Environment&lt;/h2&gt;
&lt;p&gt;AWS / ScrapyHub
Radis, MySQL / MogoDB
Elastic search
Spark&lt;/p&gt;
&lt;h2&gt;Advance&lt;/h2&gt;
&lt;p&gt;Distributed Crawling with multiple servers&lt;/p&gt;</content:encoded></item><item><title><![CDATA[Notes for authendication!]]></title><description><![CDATA[Notes for authendication Sessions Client - session cookies
Server - session-state service/server/manager problem: Memory issues: Whenever…]]></description><link>https://gatsby-starter-blog-demo.netlify.com/application-application-user-athendication</link><guid isPermaLink="false">https://gatsby-starter-blog-demo.netlify.com/application-application-user-athendication</guid><pubDate>Mon, 22 Jul 2019 00:00:00 GMT</pubDate><content:encoded>&lt;h1&gt;Notes for authendication&lt;/h1&gt;
&lt;h2&gt;Sessions&lt;/h2&gt;
&lt;p&gt;Client - session cookies
Server - session-state service/server/manager&lt;/p&gt;
&lt;p&gt;problem:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Memory issues: Whenever there are many authenticated users, the we server will consume more and more memory. Even if we use a file-bnased or external session provider, there will nonetheless be an intensive io, tcp, or socket overhead.&lt;/li&gt;
&lt;li&gt;Scalability issues: Replicating a session provider in a scalable web farm might not be an easy task and will often lead to bottlenecks or wasted resources.&lt;/li&gt;
&lt;li&gt;Cross-domain issues: Session cookies behave just like standard cookies, so they cannot be easily shard among different origins/domains. These kinds of problems can often be solved with some workarounds, yet they will often lead to insecure scenarios to make things work.&lt;/li&gt;
&lt;li&gt;Security issues: There is a wide and detailed literature of security-related issues involving sessions and session cokies:XSS attacks, cross-site request forgery etc. Most of them can be mitigated by some contermeasures, yet they can be diffcult to handle for first-hand developers.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Token (stateless)&lt;/h2&gt;
&lt;p&gt;Client - location storage / cookies
Server - auth check&lt;/p&gt;
&lt;p&gt;advantages:
It won’t store any user-specific information of the server memeory, database, session provider,or other data containers of any sort.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;refresh token&lt;/strong&gt;
It is a special kind of token that can be used to obtain a renewed access token - that allows accessing a protected resource - at any time. You can request new access tokens until the refresh token is blacklisted. Refresh tokens must be stored securely by an application becuase they essentially allow a user to remain authenticated forever.&lt;/p&gt;
&lt;h2&gt;Signatures&lt;/h2&gt;
&lt;h2&gt;Two-factore&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;The user performs a standard login with a useranme and password&lt;/li&gt;
&lt;li&gt;The server identifies the user and prompts them with an additional , user-specific request that can be only satisfied by something obtained or obtainable throught a different channel: an OTP password sent by SMS, an unique authentication card with a number of answer codes, a dynamic PIN generated by a proprietary device or a mobile app, and so on&lt;/li&gt;
&lt;li&gt;If the user gives the correct answer, they get authenticated using a standard session-based or token-based method&lt;/li&gt;
&lt;/ul&gt;</content:encoded></item><item><title><![CDATA[Application Development Notes!]]></title><description><![CDATA[Frontend technoloy choices : React has shorter learning curve since, it can be impletemented with   a type checking library developed by…]]></description><link>https://gatsby-starter-blog-demo.netlify.com/application</link><guid isPermaLink="false">https://gatsby-starter-blog-demo.netlify.com/application</guid><pubDate>Mon, 22 Jul 2019 00:00:00 GMT</pubDate><content:encoded>&lt;h2&gt;Frontend technoloy choices&lt;/h2&gt;
&lt;p&gt;&lt;code class=&quot;language-text&quot;&gt;ReactJS&lt;/code&gt;: React has shorter learning curve since, it can be impletemented with &lt;code class=&quot;language-text&quot;&gt;FlowJS&lt;/code&gt; a type checking library developed by Facebook, flux pattern is well supported by &lt;code class=&quot;language-text&quot;&gt;Redux&lt;/code&gt; library.&lt;/p&gt;
&lt;p&gt;There are also some good quality third party CSS framewok, such &lt;code class=&quot;language-text&quot;&gt;Antd&lt;/code&gt;, &lt;code class=&quot;language-text&quot;&gt;Material UI&lt;/code&gt;. However since ReactJS is using virtual DOM to update the view, it will be tricky to integrate those third party libray that manunipulate DOM directly, i.e. D3.JS.&lt;/p&gt;
&lt;p&gt;&lt;code class=&quot;language-text&quot;&gt;AngularJS (2)&lt;/code&gt;: Compare to ReactJS, Angular 2/4 is more powerful by implementing TypeScript, one of the benefit is to raise compile time errors. It is more enterprise ready framework, that is why it takes more time for developers to learn.&lt;/p&gt;
&lt;p&gt;Dependency Injection.&lt;/p&gt;
&lt;h2&gt;Backend techology choices&lt;/h2&gt;
&lt;p&gt;NodeJS&lt;/p&gt;
&lt;h2&gt;System architecture&lt;/h2&gt;
&lt;p&gt;Microservices: modularize system services ,it seems to be the trend for system design, since it fits into DevOps team with continouse delivery.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;3-Tier architectures&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;i.e. MVC architecture&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;4-Tier architectures&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Tier 1: Serverce tier&lt;/li&gt;
&lt;li&gt;Tier 2: Aggregation tier&lt;/li&gt;
&lt;li&gt;Tier 3: Delivery tier&lt;/li&gt;
&lt;li&gt;Aware of client profile (mobile, desktop, IOT, and so on), transforms data delivered by the Aggregation tier into client-specific formats. Cashed data would be fetched here, via CDN or otherwise.Selection of ads to insert into a webpage might be done here. This Tier is reponsible for optimizing data received from the Aggregation tier for an individual user. This layer can often be fully automated.&lt;/li&gt;
&lt;li&gt;Tier 4: Client tier&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Website&lt;/h2&gt;
&lt;p&gt;It is better to use traditional way to create a static sites, simply use JQuery, HTML, CSS and vanalia JavaScript.&lt;/p&gt;
&lt;p&gt;If there are more user interactions, or more UI components have to be managed, more like an application, then I will go with Angular/ React, but in general case, I will choose React, I can see React is exceptional to build widgets.&lt;/p&gt;
&lt;p&gt;Moreover, if I want to build a large platform, for example, a PAAS business, I will choose Angular, due to sctrict type checking, it is imperative to maintain large code base.&lt;/p&gt;
&lt;h2&gt;RAIL model&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Response: 100 ms to provide a response that acknowledges their action; otherwise, users will notice and get frustrated, and maybe retry the action, causing more problems down the line (we’ve all experienced this—the mad double- and triple-clicking).&lt;/li&gt;
&lt;li&gt;Animation: users will note a lag in animations if they are not performed at 60 fps. This will negatively affect the perceived performance (how the user feels about your app’s speed).&lt;/li&gt;
&lt;li&gt;Idle: Once your application is done loading, it is idle (and also will be idle between actions) until a user performs an action.&lt;/li&gt;
&lt;li&gt;Load: Optimal load time is one second (or less). That doesn’t mean your entire application loads in one second; it means the user sees content within one second. They get some sense that the current task (loading the page) is progressing in a meaningful way, rather than staring at a blank white screen. As we’ll see, this is easier said than done!&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;PRPL pattern&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;PRPL&lt;/strong&gt; stands for Push, Render, Pre-cache, Lazy-load; it’s a step-by-step process for how an ideal application should get the content it needs from the server.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;PUSH: A gentle definition of Push can be “load the critical content first, before anything else.&lt;/li&gt;
&lt;li&gt;RENDER: After (ideally) pushing all the necessary resources to the client, we render our initial route&lt;/li&gt;
&lt;li&gt;PRE-CACHED: once those assets are loaded, they will go straight into the cache and, if they’re requested again, we load them from the cache.&lt;/li&gt;
&lt;li&gt;LAZY-LOADED: This means resources needed for other routes will not be loaded.&lt;/li&gt;
&lt;/ul&gt;</content:encoded></item><item><title><![CDATA[Angular Notes!]]></title><description><![CDATA[Angular Notes Angular is consisted of six parts: Data Binding Directive (There are three kinds of directives in Angular) Components…]]></description><link>https://gatsby-starter-blog-demo.netlify.com/angular</link><guid isPermaLink="false">https://gatsby-starter-blog-demo.netlify.com/angular</guid><pubDate>Sun, 21 Jul 2019 00:00:00 GMT</pubDate><content:encoded>&lt;h1&gt;Angular Notes&lt;/h1&gt;
&lt;p&gt;Angular is consisted of six parts:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Data Binding&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Directive (There are three kinds of directives in Angular)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Components — directives with a template.&lt;/li&gt;
&lt;li&gt;are the most common of the three directives&lt;/li&gt;
&lt;li&gt;Artribuite Directive&lt;/li&gt;
&lt;li&gt;change the appearance or behaviour of an element, component, or another directive.&lt;/li&gt;
&lt;li&gt;Structural Directive&lt;/li&gt;
&lt;li&gt;change the DOM layout by adding and removing DOM elements.&lt;/li&gt;
&lt;li&gt;i.e. iterator for components&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Forms&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Template-driven forms&lt;/li&gt;
&lt;li&gt;Reactive form&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Pipe&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Applying data tranformation&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Service&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Using Provider to apply Dependency Injection for service&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Module&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Root module&lt;/li&gt;
&lt;li&gt;Feature modules&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Design pattern&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;NgRx is using Observable pattern&lt;/li&gt;
&lt;li&gt;Unidirectional Data Flow ( this is no really two way data-binding in angular 2)&lt;/li&gt;
&lt;li&gt;Dependency intejection&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Module&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;imports&lt;/em&gt; This property is used to import the modules that are required by the classes in the modules.
&lt;em&gt;providers&lt;/em&gt; This property is used to define the module’s providers. When the feature module is
loaded, the set of providers are combined with those in the root module, which means
that the feature module’s services are available throughout the application (and not just
within the module).
&lt;em&gt;declarations&lt;/em&gt; This property is used to specify the directives, components, and pipes in the module.
This property must contain the classes that are used within the module and those that are
exposed by the module to the rest of the application.
&lt;em&gt;exports&lt;/em&gt; This property is used to define the public exports from the module. It contains some or all
of the directives, components, and pipes from the declarations property and some or all
of the modules from the imports property.&lt;/p&gt;
&lt;h2&gt;RxJS&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;next(value)&lt;/em&gt; This method creates a new event using the specified value.
&lt;em&gt;error(errorObject)&lt;/em&gt; This method reports an error, described using the argument, which can be any
object.
&lt;em&gt;complete()&lt;/em&gt; This method ends the sequence, indicating that no further events will be sent.&lt;/p&gt;
&lt;h2&gt;in-memory-web-api.&lt;/h2&gt;
&lt;p&gt;it is used to simulate HTTP requests using data that has been defined locally. This provides a way to isolate a data source
class and ensure that only its behavior is being tested&lt;/p&gt;
&lt;h2&gt;Test&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Jasmine.JS&lt;/em&gt; BDD test for Angular&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Define test component in testname.spec.ts&lt;/li&gt;
&lt;li&gt;Create test component&lt;/li&gt;
&lt;li&gt;describe test behaviour&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Router bug&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://stackoverflow.com/questions/38120756/angular2-router-navigate-refresh-page&quot;&gt;https://stackoverflow.com/questions/38120756/angular2-router-navigate-refresh-page&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Input type (type = “button) is important to make naviation animation works in angular 4, without specifying type, it works on IE11 and Edge browsers, but would reload the application in Chrome.&lt;/p&gt;</content:encoded></item><item><title><![CDATA[Notes for API engineering!]]></title><description><![CDATA[RPC vs REST RPC ( Command-based ) style endpoints are great when you want only one job done well. This makes it useful to one or two app…]]></description><link>https://gatsby-starter-blog-demo.netlify.com/api</link><guid isPermaLink="false">https://gatsby-starter-blog-demo.netlify.com/api</guid><pubDate>Sun, 21 Jul 2019 00:00:00 GMT</pubDate><content:encoded>&lt;h2&gt;RPC vs REST&lt;/h2&gt;
&lt;p&gt;RPC (&lt;strong&gt;Command-based&lt;/strong&gt;) style endpoints are great when you want only one job done well. This makes it useful to one or two app clients because it is niche a service. RPC endpoints can implement business logic inside the service, given that it only does one thing. This adds simplicity and clarity to the service.&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;http&quot;&gt;&lt;pre class=&quot;language-http&quot;&gt;&lt;code class=&quot;language-http&quot;&gt;GET /someoperation?data=anId

POST /anotheroperation
{
  &quot;data&quot;:&quot;anId&quot;;
  &quot;anotherdata&quot;:&quot;another value&quot;
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;For a REST (&lt;strong&gt;resource-based&lt;/strong&gt;) endpoint, you must treat it like a resource that provides domain data. The reward is you are now segregating data into separate domains. This makes it useful for when you have any number of apps requesting data. This approach attempts to decouple data from application or business logic.&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;http&quot;&gt;&lt;pre class=&quot;language-http&quot;&gt;&lt;code class=&quot;language-http&quot;&gt;GET /someresources/anId

PUT /someresources/anId
{&quot;anotherdata&quot;:&quot;another value&quot;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</content:encoded></item><item><title><![CDATA[Agile Notes!]]></title><description><![CDATA[Methodology extreme programming scrum kanban Cargo Cult Being envious of the success and benefits of Agile, many companies adopt the…]]></description><link>https://gatsby-starter-blog-demo.netlify.com/agile</link><guid isPermaLink="false">https://gatsby-starter-blog-demo.netlify.com/agile</guid><pubDate>Sun, 21 Jul 2019 00:00:00 GMT</pubDate><content:encoded>&lt;h2&gt;Methodology&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;extreme programming&lt;/li&gt;
&lt;li&gt;scrum&lt;/li&gt;
&lt;li&gt;kanban&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Cargo Cult&lt;/h2&gt;
&lt;p&gt;Being envious of the success and benefits of Agile, many companies adopt the superficial trappings of Agile, renaming the meetings as “stand ups” and calling management reviews “retrospectives”. But in practice, nothing changes. It’s still the same primitive management driven hierarchical organization, micromanaging the teams, using outdated waterfall practices, and completely failing to grasp the core principles of agility.&lt;/p&gt;
&lt;h1&gt;The Scrum team&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Product Owner (PO):collects requirements from customers (internal or external) and produces the requirements documents. The PO constantly aligns with customers and determines the scope of work and change in the scope, so the PO will get results from the Sprints. The PO is responsible for providing all the necessary product-related information required by the team and providing requirements.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Scrum Master ( ScMa ) :is the servant-leader of the team who helps the team to deliver based on requirements. The ScMa organizes the process and moderates the meetings that will enable the team to deliver. Also, the ScMa provides statuses to the PO or any stakeholders. The ScMa is in charge of resolution of any block and impediments the team faces. The ScMa shelters and protects the team from external teams and stakeholders.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The Architect (Arc)is the technical lead in the team&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The Quality Manager (QM) or Quality Engineer(QE) is the team member responsible for quality management of the product. The QM organizes the quality process in the team, educates the PO and ScMa on quality best practices, and provides quality requirements to the team based on feedback from the PO, industry standards, and best practices (Including performance, security, usability, accessibility etc.).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Developers (DEV) estimate and commit to the estimation on a Sprint basis. They constantly improve the accuracy of the estimation and self-improve from Sprint to Sprint without micromanagement from other roles and managers. Developers distribute between the different expert roles—for example performance, security, and user interface designer.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A Technical Writer (TW) writes supporting documentation for the project. This role can be centralized, since it is usually not required to have a full-time technical writer in the team. However, technical documentation also can be produced by any other role/roles in the team as an additional responsibility.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;</content:encoded></item><item><title><![CDATA[Data-intensive Architecture Notes!]]></title><description><![CDATA[Data-intensive architecute A data-intensive application Many applications today are data-intensive, as opposed to compute-intensive. Raw CPU…]]></description><link>https://gatsby-starter-blog-demo.netlify.com/architecture-data-itensive</link><guid isPermaLink="false">https://gatsby-starter-blog-demo.netlify.com/architecture-data-itensive</guid><pubDate>Sun, 21 Jul 2019 00:00:00 GMT</pubDate><content:encoded>&lt;h1&gt;Data-intensive architecute&lt;/h1&gt;
&lt;h2&gt;A data-intensive application&lt;/h2&gt;
&lt;p&gt;Many applications today are data-intensive, as opposed to compute-intensive. Raw CPU power is rarely a limiting factor for these applications—bigger problems are usually the amount of data, the complexity of data, and the speed at which it is changing.&lt;/p&gt;
&lt;p&gt;A data-intensive application is typically built from standard building blocks that provide commonly needed functionality. For example, many applications need to:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Store data so that they, or another application, can find it again later (databases)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Remember the result of an expensive operation, to speed up reads (caches)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Allow users to search data by keyword or filter it in various ways (search indexes)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Send a message to another process, to be handled asynchronously (stream processing)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Periodically crunch a large amount of accumulated data (batch processing)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;three concerns that are important in most software systems:&lt;/h2&gt;
&lt;p&gt;&lt;code class=&quot;language-text&quot;&gt;Reliability&lt;/code&gt;
The system should continue to work correctly (performing the correct function at the desired level of performance) even in the face of adversity (hardware or software faults, and even human error). See “Reliability”.&lt;/p&gt;
&lt;p&gt;&lt;code class=&quot;language-text&quot;&gt;Scalability&lt;/code&gt;
As the system grows (in data volume, traffic volume, or complexity), there should be reasonable ways of dealing with that growth. See “Scalability”.&lt;/p&gt;
&lt;p&gt;&lt;code class=&quot;language-text&quot;&gt;Maintainability&lt;/code&gt;
Over time, many different people will work on the system (engineering and operations, both maintaining current behavior and adapting the system to new use cases), and they should all be able to work on it productively. See “Maintainability”.&lt;/p&gt;
&lt;h2&gt;Lagacy system&lt;/h2&gt;
&lt;p&gt;Many people working on software systems dislike maintenance of so-called legacy systems—perhaps it involves fixing other people’s mistakes, or working with platforms that are now outdated, or systems that were forced to do things they were never intended for&lt;/p&gt;</content:encoded></item><item><title><![CDATA[Notes for testing!]]></title><description><![CDATA[Notes for test Unit test The unit tests are used to prove the smallest testable part of a computer program.In this sense, the great…]]></description><link>https://gatsby-starter-blog-demo.netlify.com/testing</link><guid isPermaLink="false">https://gatsby-starter-blog-demo.netlify.com/testing</guid><pubDate>Sun, 21 Jul 2019 00:00:00 GMT</pubDate><content:encoded>&lt;h1&gt;Notes for test&lt;/h1&gt;
&lt;h2&gt;Unit test&lt;/h2&gt;
&lt;p&gt;The unit tests are used to prove the smallest testable part of a computer program.In this sense, the great challenge is to write code that is testable; otherwise, it will be impossible to apply the unit tests.&lt;/p&gt;
&lt;p&gt;When we create the unit test, we have to use a mechanism so that the function test does not touch the database. The mechanism is commonly known as a &lt;strong&gt;mock&lt;/strong&gt;.When applying a mock to the unit test, we isolate the function we want to test, then any possible changes in the database will not create conflict in the unit test scenarios.&lt;/p&gt;
&lt;h2&gt;Integration tests&lt;/h2&gt;
&lt;p&gt;Like unit tests, integration tests must also be deterministic, but they do not prove only an isolated segment of the code. Integration tests, in the case of microservices, will validate the entire flow from the starting point of the test to the last interaction; it could be a vendor app or a database, as an example.&lt;/p&gt;
&lt;h2&gt;End-to-end tests&lt;/h2&gt;
&lt;p&gt;The end-to-end tests are conceptually similar to integration tests, but they validate the entire business flow of the application. The main purpose of this type of test is to check whether any flow stages are corrupted. Many developers get confused about the difference between end-to-end and integration tests.&lt;/p&gt;
&lt;p&gt;examples:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Create a user.&lt;/li&gt;
&lt;li&gt;Create a news article for each type of news service (famous, politics, and sports).&lt;/li&gt;
&lt;li&gt;Search for all news articles created in the test by sending the user_id function in the request cookie.&lt;/li&gt;
&lt;li&gt;Validate the recommendations created for the user.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Signature tests&lt;/h2&gt;
&lt;p&gt;Imagine a scenario where we have several development teams working on different microservices of the same application. These microservices have some communication between them; there is a kind of contract between them that is the payload of the microservice, also known as the &lt;strong&gt;Service Signature&lt;/strong&gt;. One of the development teams modifies the signature of the microservice causing errors in other parts of the application.&lt;/p&gt;
&lt;p&gt;When a microservice has the signature changed, a task must be generated for the other development teams responsible for microservices that integrate with this signature.&lt;/p&gt;
&lt;h2&gt;Monkey tests&lt;/h2&gt;
&lt;p&gt;Monkey tests are usually automated tests with random values that target identified errors in the application. Normally, the errors that emerge in this type of test are due to a failure of treatment in the input or slowness in the treatment of input owing to the stress of the application.&lt;/p&gt;
&lt;p&gt;In general, the monkey test is useful for identifying out-of-the-box errors.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Chaos Monkey&lt;/strong&gt; has the following test categories:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Chaos Gorilla: This simulates the unavailability of an entire zone of availability&lt;/li&gt;
&lt;li&gt;Conformity Monkey: This closes instances that do not adhere to best practices&lt;/li&gt;
&lt;li&gt;Doctor Monkey: This performs performance checks (similar to a CPU)&lt;/li&gt;
&lt;li&gt;Janitor Monkey: This searches for unused resources and deletes them&lt;/li&gt;
&lt;li&gt;Latency Monkey: This creates artificial delays in client-server communication&lt;/li&gt;
&lt;li&gt;Security Monkey: This encounters security vulnerabilities, such as non-security groups configured properly&lt;/li&gt;
&lt;/ul&gt;</content:encoded></item><item><title><![CDATA[Datebase Notes!]]></title><description><![CDATA[What are common use cases for MongoDB? MongoDB is a general purpose database that is used for a variety of use cases. The most common use…]]></description><link>https://gatsby-starter-blog-demo.netlify.com/database-compare</link><guid isPermaLink="false">https://gatsby-starter-blog-demo.netlify.com/database-compare</guid><pubDate>Thu, 31 Jan 2019 00:00:00 GMT</pubDate><content:encoded>&lt;h2&gt;What are common use cases for MongoDB?&lt;/h2&gt;
&lt;p&gt;MongoDB is a general purpose database that is used for a variety of use cases. The most common use cases for MongoDB include Single View, Internet of Things, Mobile, Real-Time Analytics, Personalization, Catalog, and Content Management.&lt;/p&gt;
&lt;h2&gt;When would MySQL be a better fit?&lt;/h2&gt;
&lt;p&gt;While most modern applications require a flexible, scalable system like MongoDB, there are use cases for which a relational database like MySQL would be better suited. Applications that require complex, multi-row transactions (e.g., a double-entry bookkeeping system) would be good examples. MongoDB is not a drop-in replacement for legacy applications built around the relational data model and SQL.&lt;/p&gt;
&lt;p&gt;A concrete example would be the booking engine behind a travel reservation system, which also typically involves complex transactions. While the core booking engine might run on MySQL, those parts of the app that engage with users – serving up content, integrating with social networks, managing sessions – would be better placed in MongoDB&lt;/p&gt;</content:encoded></item><item><title><![CDATA[Dotnet Notes!]]></title><description><![CDATA[Dotnet notes Dotnet MVC Dotnet API Duck Typing Install Angular 5 app with dotnet cli Installl the templates Create a new Angular App Change…]]></description><link>https://gatsby-starter-blog-demo.netlify.com/dotnet-readme</link><guid isPermaLink="false">https://gatsby-starter-blog-demo.netlify.com/dotnet-readme</guid><pubDate>Thu, 31 Jan 2019 00:00:00 GMT</pubDate><content:encoded>&lt;h1&gt;Dotnet notes&lt;/h1&gt;
&lt;h2&gt;Dotnet MVC&lt;/h2&gt;
&lt;h2&gt;Dotnet API&lt;/h2&gt;
&lt;h2&gt;Duck Typing&lt;/h2&gt;
&lt;h2&gt;Install Angular 5 app with dotnet cli&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Installl the templates&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;bash&quot;&gt;&lt;pre class=&quot;language-bash&quot;&gt;&lt;code class=&quot;language-bash&quot;&gt;dotnet new --install Microsoft.DotNet.Web.Spa.ProjectTemplates::2.0.0-rc1-final&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;ol start=&quot;2&quot;&gt;
&lt;li&gt;Create a new Angular App&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;bash&quot;&gt;&lt;pre class=&quot;language-bash&quot;&gt;&lt;code class=&quot;language-bash&quot;&gt;dotnet new angular -o ProjectName&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;ol start=&quot;3&quot;&gt;
&lt;li&gt;Change Enviroment variable to “Development”&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;bash&quot;&gt;&lt;pre class=&quot;language-bash&quot;&gt;&lt;code class=&quot;language-bash&quot;&gt;SET ASPNETCORE_Environment&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;Development&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;ol start=&quot;4&quot;&gt;
&lt;li&gt;Buidl the application&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;bash&quot;&gt;&lt;pre class=&quot;language-bash&quot;&gt;&lt;code class=&quot;language-bash&quot;&gt;dotnet build&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Or&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;bash&quot;&gt;&lt;pre class=&quot;language-bash&quot;&gt;&lt;code class=&quot;language-bash&quot;&gt;ASPNETCORE_ENVIRONMENT&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;Development dotnet &lt;span class=&quot;token function&quot;&gt;watch&lt;/span&gt; run

&lt;span class=&quot;token comment&quot;&gt;## migrate a database&lt;/span&gt;
**Code-First** Migrations: giving the developer a chance to alter the Database schema without having to drop/recreate the whole thing &lt;span class=&quot;token keyword&quot;&gt;in&lt;/span&gt; Production.

``` &lt;span class=&quot;token function&quot;&gt;bash&lt;/span&gt;
dotnet ef migrations add &lt;span class=&quot;token string&quot;&gt;&quot;Identity&quot;&lt;/span&gt; -o &lt;span class=&quot;token string&quot;&gt;&quot;Data/Migrations&quot;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;update a database&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;option 1: update&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;bash&quot;&gt;&lt;pre class=&quot;language-bash&quot;&gt;&lt;code class=&quot;language-bash&quot;&gt;dotnet ef database update&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;option 2: drop and recreate&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;bash&quot;&gt;&lt;pre class=&quot;language-bash&quot;&gt;&lt;code class=&quot;language-bash&quot;&gt;dotnet ef database drop
dotnet ef database update&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;bash&quot;&gt;&lt;pre class=&quot;language-bash&quot;&gt;&lt;code class=&quot;language-bash&quot;&gt;ASPNETCORE_ENVIRONMENT&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;Development dotnet run&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;Depency injection&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Name&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;AddTransient&amp;#x3C;service,implType&gt;()&lt;/td&gt;
&lt;td&gt;This method tells the service provider to create a new instance of the implementation type for every dependency on the service type. See the “Using the Transient Life Cycle” section.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;AddTransient&lt;service&gt;()&lt;/td&gt;
&lt;td&gt;This method is used to register a single type, which will be instantiated for every dependency, as described in the “Using Dependency Injection for Concrete Types” section.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;AddTransient&lt;service&gt;(factoryFunc)&lt;/td&gt;
&lt;td&gt;This method is used to register a factory function that will be invoked to create an implementation object for every dependency on the service type, as described in the “Using a Factory Function” section.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;AddScoped&amp;#x3C;service, implType&gt;() AddScoped&lt;service&gt;() AddScoped&lt;service&gt;(factoryFunc)&lt;/td&gt;
&lt;td&gt;These methods tell the service provider to reuse instances of the implementation type so that all service requests made by components associated with a common scope, which is usually a single HTTP request, share the same object. These methods follow the same pattern as the corresponding AddTransientmethods. See the “Using the Scoped Life Cycle” section.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;AddSingleton&amp;#x3C;service, implType&gt;() AddSingleton&lt;service&gt;() AddSingleton&amp;#x3C;service(factoryFunc)&lt;/td&gt;
&lt;td&gt;These methods tell the service provider to create a new instance of the implementation type for the first service request and then reuse it for every subsequent service request. See the “Using the Singleton Life Cycle” section.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;AddSingleton&lt;service&gt;(instance)&lt;/td&gt;
&lt;td&gt;This method provides the service provider with an object that should be used to service all service requests. The service provider will not create any new objects.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2&gt;Razor&lt;/h2&gt;
&lt;h3&gt;View location Expender&lt;/h3&gt;
&lt;p&gt;Razor uses view location expanders to build up a list of locations that should be searched for a view. View location expanders implement the IViewLocationExpander interface&lt;/p&gt;
&lt;h2&gt;Claim and Policy&lt;/h2&gt;
&lt;p&gt;A claim is a piece of information about the user, along with some information about where the information came from.&lt;/p&gt;
&lt;p&gt;Policy works with claims to manage user access to the application more flexibly than with standard roles.&lt;/p&gt;
&lt;h2&gt;Model convention&lt;/h2&gt;</content:encoded></item><item><title><![CDATA[Design Pattern Notes!]]></title><description><![CDATA[Behavioral Pattern Strategy pattern 
In Strategy pattern, a class behavior or its algorithm can be changed at run time. This type of design…]]></description><link>https://gatsby-starter-blog-demo.netlify.com/design-pattern</link><guid isPermaLink="false">https://gatsby-starter-blog-demo.netlify.com/design-pattern</guid><pubDate>Thu, 31 Jan 2019 00:00:00 GMT</pubDate><content:encoded>&lt;h2&gt;Behavioral Pattern&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Strategy pattern&lt;/strong&gt;
In Strategy pattern, a class behavior or its algorithm can be changed at run time. This type of design pattern comes under behavior pattern.&lt;/p&gt;
&lt;p&gt;In Strategy pattern, we create objects which represent various strategies and a context object whose behavior varies as per its strategy object. The strategy object changes the executing algorithm of the context object.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Command pattern&lt;/strong&gt;
Command pattern is a data driven design pattern and falls under behavioral pattern category. A request is wrapped under an object as command and passed to invoker object. Invoker object looks for the appropriate object which can handle this command and passes the command to the corresponding object which executes the command.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Observer pattern&lt;/strong&gt;
Observer pattern is used when there is one-to-many relationship between objects such as if one object is modified, its depenedent objects are to be notified automatically. Observer pattern falls under behavioral pattern category.&lt;/p&gt;
&lt;h2&gt;Structural Pattern&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Adapter pattern&lt;/strong&gt;
Adapter pattern works as a bridge between two incompatible interfaces. This pattern involves a single class which is responsible to join functionalities of independent or incompatible interfaces.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Decorator pattern&lt;/strong&gt;
Decorator pattern allows a user to add new functionality to an existing object without altering its structure. This type of design pattern comes under structural pattern as this pattern acts as a wrapper to existing class.&lt;/p&gt;
&lt;p&gt;This pattern creates a decorator class which wraps the original class and provides additional functionality keeping class methods signature intact.&lt;/p&gt;</content:encoded></item><item><title><![CDATA[AWS Notes!]]></title><description><![CDATA[Install Node app in AWS Installing node and system dependencies]]></description><link>https://gatsby-starter-blog-demo.netlify.com/dev-ops-aws</link><guid isPermaLink="false">https://gatsby-starter-blog-demo.netlify.com/dev-ops-aws</guid><pubDate>Thu, 31 Jan 2019 00:00:00 GMT</pubDate><content:encoded>&lt;h2&gt;Install Node app in AWS&lt;/h2&gt;
&lt;h3&gt;Installing node and system dependencies&lt;/h3&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;bash&quot;&gt;&lt;pre class=&quot;language-bash&quot;&gt;&lt;code class=&quot;language-bash&quot;&gt;&lt;span class=&quot;token function&quot;&gt;curl&lt;/span&gt; -sL https://deb.nodesource.com/setup_8.x &lt;span class=&quot;token operator&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;sudo&lt;/span&gt; -E &lt;span class=&quot;token function&quot;&gt;bash&lt;/span&gt; -
&lt;span class=&quot;token function&quot;&gt;sudo&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;apt-get&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;install&lt;/span&gt; -y nodejs&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</content:encoded></item><item><title><![CDATA[ELK Stack Notes!]]></title><description><![CDATA[ELK Stack notes Elasticsearch Increase production virtual memory
 Filebeat Start Filebeat
 Config Filebeat
 To see a list of available…]]></description><link>https://gatsby-starter-blog-demo.netlify.com/dev-ops-elk</link><guid isPermaLink="false">https://gatsby-starter-blog-demo.netlify.com/dev-ops-elk</guid><pubDate>Thu, 31 Jan 2019 00:00:00 GMT</pubDate><content:encoded>&lt;h1&gt;ELK Stack notes&lt;/h1&gt;
&lt;h2&gt;Elasticsearch&lt;/h2&gt;
&lt;p&gt;Increase production virtual memory
&lt;code class=&quot;language-text&quot;&gt;sudo sysctl -w vm.max_map_count=262144&lt;/code&gt;&lt;/p&gt;
&lt;h2&gt;Filebeat&lt;/h2&gt;
&lt;p&gt;Start Filebeat
&lt;code class=&quot;language-text&quot;&gt;sudo /etc/init.d/filebeat start&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Config Filebeat
&lt;code class=&quot;language-text&quot;&gt;sudo vi /etc/filebeat/filebeat.yml&lt;/code&gt;&lt;/p&gt;
&lt;h1&gt;To see a list of available indexes&lt;/h1&gt;
&lt;p&gt;curl ‘localhost:9200/_cat/indices?v’&lt;/p&gt;</content:encoded></item><item><title><![CDATA[Docker Notes!]]></title><description><![CDATA[Userful commands Stop all containers docker stop $(docker ps -a -q) Delete all containers docker rm $(docker ps -a -q) Delete all images…]]></description><link>https://gatsby-starter-blog-demo.netlify.com/dev-ops-docker</link><guid isPermaLink="false">https://gatsby-starter-blog-demo.netlify.com/dev-ops-docker</guid><pubDate>Thu, 31 Jan 2019 00:00:00 GMT</pubDate><content:encoded>&lt;h1&gt;Userful commands&lt;/h1&gt;
&lt;h2&gt;Stop all containers&lt;/h2&gt;
&lt;p&gt;docker stop $(docker ps -a -q)&lt;/p&gt;
&lt;h3&gt;Delete all containers&lt;/h3&gt;
&lt;p&gt;docker rm $(docker ps -a -q)&lt;/p&gt;
&lt;h3&gt;Delete all images&lt;/h3&gt;
&lt;p&gt;docker rmi $(docker images -q)&lt;/p&gt;
&lt;p&gt; If you need to go inside the container you can use the exec command:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;text&quot;&gt;&lt;pre class=&quot;language-text&quot;&gt;&lt;code class=&quot;language-text&quot;&gt;# Enter the container
$ docker exec -it &amp;lt;container id&amp;gt; /bin/bash&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;Production &lt;em&gt;docker-compose&lt;/em&gt;&lt;/h2&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;bash&quot;&gt;&lt;pre class=&quot;language-bash&quot;&gt;&lt;code class=&quot;language-bash&quot;&gt;$ docker-compose build web
$ docker-compose up --no-deps -d web&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This will first rebuild the image for &lt;code class=&quot;language-text&quot;&gt;web&lt;/code&gt; and then stop, destroy, and recreate just the web service. The &lt;code class=&quot;language-text&quot;&gt;--no-deps&lt;/code&gt; flag prevents Compose from also recreating any services which &lt;code class=&quot;language-text&quot;&gt;web&lt;/code&gt; depends on.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;clean up logs&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;bash&quot;&gt;&lt;pre class=&quot;language-bash&quot;&gt;&lt;code class=&quot;language-bash&quot;&gt;truncate -s 0 /var/lib/docker/containers/*/*-json.log&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</content:encoded></item><item><title><![CDATA[General DevOps Notes!]]></title><description><![CDATA[General notes Portable vagrant with docker This is should work only with services, such as database. For project that you will need to see…]]></description><link>https://gatsby-starter-blog-demo.netlify.com/dev-ops-general</link><guid isPermaLink="false">https://gatsby-starter-blog-demo.netlify.com/dev-ops-general</guid><pubDate>Thu, 31 Jan 2019 00:00:00 GMT</pubDate><content:encoded>&lt;h1&gt;General notes&lt;/h1&gt;
&lt;h2&gt;Portable vagrant with docker&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;This is should work only with services, such as database.&lt;/li&gt;
&lt;li&gt;For project that you will need to see debug logs , should use docker instead of using docker provider by vagrant. &lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;AWS elastic search choice&lt;/h2&gt;
&lt;p&gt;t2.small&lt;/p&gt;
&lt;h2&gt;Nginx local redirect&lt;/h2&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;nginx&quot;&gt;&lt;pre class=&quot;language-nginx&quot;&gt;&lt;code class=&quot;language-nginx&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;auth_basic&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&quot;Restricted Content&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;token keyword&quot;&gt;auth_basic_user_file&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;/&lt;/span&gt;etc&lt;span class=&quot;token operator&quot;&gt;/&lt;/span&gt;nginx&lt;span class=&quot;token operator&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;htpasswd&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;token keyword&quot;&gt;proxy_pass&lt;/span&gt; &lt;span class=&quot;token keyword&quot;&gt;https&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;&amp;lt;&lt;/span&gt;service&lt;span class=&quot;token operator&quot;&gt;&gt;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;&amp;lt;&lt;/span&gt;domain&lt;span class=&quot;token operator&quot;&gt;&gt;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;&amp;lt;&lt;/span&gt;port&lt;span class=&quot;token operator&quot;&gt;&gt;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;Find matching string with following n line&lt;/h2&gt;
&lt;p&gt;After&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;bash&quot;&gt;&lt;pre class=&quot;language-bash&quot;&gt;&lt;code class=&quot;language-bash&quot;&gt;&lt;span class=&quot;token function&quot;&gt;grep&lt;/span&gt; -i -A n &lt;span class=&quot;token variable&quot;&gt;${msg}&lt;/span&gt; filename&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Before&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;bash&quot;&gt;&lt;pre class=&quot;language-bash&quot;&gt;&lt;code class=&quot;language-bash&quot;&gt;&lt;span class=&quot;token function&quot;&gt;grep&lt;/span&gt; -i -B n &lt;span class=&quot;token variable&quot;&gt;${msg}&lt;/span&gt; filename&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Both&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;bash&quot;&gt;&lt;pre class=&quot;language-bash&quot;&gt;&lt;code class=&quot;language-bash&quot;&gt;&lt;span class=&quot;token function&quot;&gt;grep&lt;/span&gt; -i -C n &lt;span class=&quot;token variable&quot;&gt;${msg}&lt;/span&gt; filename&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</content:encoded></item><item><title><![CDATA[Git Notes!]]></title><description><![CDATA[Git Notes Revert file to specific commit git checkout commit_id — file1/to/restore file2/to/restore Reset commit git reset HEAD~ Reset index…]]></description><link>https://gatsby-starter-blog-demo.netlify.com/git-git</link><guid isPermaLink="false">https://gatsby-starter-blog-demo.netlify.com/git-git</guid><pubDate>Thu, 31 Jan 2019 00:00:00 GMT</pubDate><content:encoded>&lt;h1&gt;Git Notes&lt;/h1&gt;
&lt;h2&gt;Revert file to specific commit&lt;/h2&gt;
&lt;p&gt;git checkout commit_id — file1/to/restore file2/to/restore&lt;/p&gt;
&lt;h2&gt;Reset commit&lt;/h2&gt;
&lt;p&gt;git reset HEAD~&lt;/p&gt;
&lt;h2&gt;Reset index&lt;/h2&gt;
&lt;p&gt;git reset&lt;/p&gt;
&lt;h2&gt;Ignore folder / directory&lt;/h2&gt;
&lt;p&gt;directory_name/&lt;/p&gt;
&lt;h2&gt;Amend a git commit message&lt;/h2&gt;
&lt;p&gt;git commit —amend -m “New commit message”&lt;/p&gt;
&lt;h2&gt;Revert git to commit id&lt;/h2&gt;
&lt;p&gt;git reset —hard f414f31
git reset —soft HEAD@{1}
git commit -m “Reverting to the state of the project at f414f31”&lt;/p&gt;
&lt;h2&gt;Clean up your local branches after merge and delete in GitHub&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;List branches in local machine
The command &lt;code class=&quot;language-text&quot;&gt;git branch -a&lt;/code&gt; shows the test branch feature-collaboration is present on local and also present on remote&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Prune/Cleanup the local references to remote branch&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The command &lt;code class=&quot;language-text&quot;&gt;git remote prune origin --dry-run&lt;/code&gt; lists branches that can be deleted/pruned on your local. An option &lt;code class=&quot;language-text&quot;&gt;--dry-run&lt;/code&gt; is needed.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Now go ahead and actually prune/cleanup the local references by running the command &lt;code class=&quot;language-text&quot;&gt;git remote prune origin&lt;/code&gt;. Note that you don’t need an option &lt;code class=&quot;language-text&quot;&gt;--dry-run&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Again, run the command &lt;code class=&quot;language-text&quot;&gt;git branch -a&lt;/code&gt; will show the local status of branches.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Delete local branch&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Rename a local and remote branch&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Rename your local branch.
If you are on the branch you want to rename:&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;git&quot;&gt;&lt;pre class=&quot;language-git&quot;&gt;&lt;code class=&quot;language-git&quot;&gt;git branch -m new-name&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;If you are on a different branch:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;git&quot;&gt;&lt;pre class=&quot;language-git&quot;&gt;&lt;code class=&quot;language-git&quot;&gt;git branch -m old-name new-name&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;ol&gt;
&lt;li&gt;Delete the old-name remote branch and push the new-name local branch.&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;git&quot;&gt;&lt;pre class=&quot;language-git&quot;&gt;&lt;code class=&quot;language-git&quot;&gt;git push origin :old-name new-name&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;ol&gt;
&lt;li&gt;Reset the upstream branch for the new-name local branch.
Switch to the branch and then:&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;git&quot;&gt;&lt;pre class=&quot;language-git&quot;&gt;&lt;code class=&quot;language-git&quot;&gt;git push origin -u new-name&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</content:encoded></item><item><title><![CDATA[Vagrant Notes!]]></title><description><![CDATA[Clean vagrant build vagrant global-status —prune - Prunes invalid entries from the list. This is much more time consuming than simply…]]></description><link>https://gatsby-starter-blog-demo.netlify.com/dev-ops-vagrant</link><guid isPermaLink="false">https://gatsby-starter-blog-demo.netlify.com/dev-ops-vagrant</guid><pubDate>Thu, 31 Jan 2019 00:00:00 GMT</pubDate><content:encoded>&lt;h2&gt;Clean vagrant build&lt;/h2&gt;
&lt;p&gt;vagrant global-status —prune - Prunes invalid entries from the list. This is much more time consuming than simply listing the entries.&lt;/p&gt;
&lt;h1&gt;Setup vagrant with docker&lt;/h1&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;ruby&quot;&gt;&lt;pre class=&quot;language-ruby&quot;&gt;&lt;code class=&quot;language-ruby&quot;&gt;config&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;vm&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;box &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&quot;ubuntu/trusty64&quot;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h1&gt;Set vagrant up default box&lt;/h1&gt;
&lt;p&gt;By passing &lt;code class=&quot;language-text&quot;&gt;primary&lt;/code&gt; flag to the the machine definition to start the machine as default machine when passing &lt;code class=&quot;language-text&quot;&gt;vigrant up&lt;/code&gt;&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;ruby&quot;&gt;&lt;pre class=&quot;language-ruby&quot;&gt;&lt;code class=&quot;language-ruby&quot;&gt;&lt;span class=&quot;token comment&quot;&gt;# -*- mode: ruby -*-&lt;/span&gt;
&lt;span class=&quot;token comment&quot;&gt;# vi: set ft=ruby :&lt;/span&gt;
&lt;span class=&quot;token constant&quot;&gt;VAGRANTFILE_API_VERSION&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&quot;2&quot;&lt;/span&gt;
    &lt;span class=&quot;token constant&quot;&gt;Vagrant&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;configure&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token constant&quot;&gt;VAGRANTFILE_API_VERSION&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token keyword&quot;&gt;do&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;|&lt;/span&gt;config&lt;span class=&quot;token operator&quot;&gt;|&lt;/span&gt;
        config&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;vm&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;define &lt;span class=&quot;token string&quot;&gt;&quot;web&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; primary&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;token keyword&quot;&gt;true&lt;/span&gt; &lt;span class=&quot;token keyword&quot;&gt;do&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;|&lt;/span&gt;web&lt;span class=&quot;token operator&quot;&gt;|&lt;/span&gt;
        web&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;vm&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;box &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&quot;puppetlabs/ubuntu-14.04-32-nocm&quot;&lt;/span&gt;
    &lt;span class=&quot;token keyword&quot;&gt;end&lt;/span&gt;
&lt;span class=&quot;token keyword&quot;&gt;end&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;We’ll need to install a service that will run on port 80 of the guest machine. To do
this, we’ll add a simple provisioning command. The complete Vagrantfile now looks
like this:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;ruby&quot;&gt;&lt;pre class=&quot;language-ruby&quot;&gt;&lt;code class=&quot;language-ruby&quot;&gt;web&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;vm&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;provision &lt;span class=&quot;token string&quot;&gt;&quot;shell&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; inline&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&quot;apt-get install -y nginx&quot;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;With the auto_correct option, Vagrant will first attempt to connect to the specified
port (in this example, 8888), then fail over to a different port if the one specified is being
used by another process.&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;ruby&quot;&gt;&lt;pre class=&quot;language-ruby&quot;&gt;&lt;code class=&quot;language-ruby&quot;&gt;web&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;vm&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;network &lt;span class=&quot;token string&quot;&gt;&quot;forwarded_port&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; guest&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;80&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; host&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;8888&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; auto_correct&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;token keyword&quot;&gt;true&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;To enable the GUI, we will need to add a provider-specific block to the configuration.
In this case, the provider is “virtualbox”.&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;ruby&quot;&gt;&lt;pre class=&quot;language-ruby&quot;&gt;&lt;code class=&quot;language-ruby&quot;&gt;&lt;span class=&quot;token comment&quot;&gt;# -*- mode: ruby -*-&lt;/span&gt;
&lt;span class=&quot;token comment&quot;&gt;# vi: set ft=ruby :&lt;/span&gt;
&lt;span class=&quot;token constant&quot;&gt;VAGRANTFILE_API_VERSION&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&quot;2&quot;&lt;/span&gt;
&lt;span class=&quot;token constant&quot;&gt;Vagrant&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;configure&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token constant&quot;&gt;VAGRANTFILE_API_VERSION&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token keyword&quot;&gt;do&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;|&lt;/span&gt;config&lt;span class=&quot;token operator&quot;&gt;|&lt;/span&gt;
    config&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;vm&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;box &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&quot;chad-thompson/ubuntu-trusty64-gui&quot;&lt;/span&gt; config&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;
    vm&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;provider &lt;span class=&quot;token string&quot;&gt;&quot;virtualbox&quot;&lt;/span&gt; &lt;span class=&quot;token keyword&quot;&gt;do&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;|&lt;/span&gt;vbox&lt;span class=&quot;token operator&quot;&gt;|&lt;/span&gt;
        vbox&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;gui &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token keyword&quot;&gt;true&lt;/span&gt;
    &lt;span class=&quot;token keyword&quot;&gt;end&lt;/span&gt;
&lt;span class=&quot;token keyword&quot;&gt;end&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;synced_folder&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;ruby&quot;&gt;&lt;pre class=&quot;language-ruby&quot;&gt;&lt;code class=&quot;language-ruby&quot;&gt;web&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;vm&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;synced_folder &lt;span class=&quot;token string&quot;&gt;&quot;vagrantsite/&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&quot;/opt/vagrantsite&quot;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This will link the &lt;code class=&quot;language-text&quot;&gt;vagrantsite&lt;/code&gt; directory we created in step 1 to the &lt;code class=&quot;language-text&quot;&gt;/opt/vagrantsite&lt;/code&gt; directory on the guest machine.&lt;/p&gt;
&lt;h1&gt;Ansible - is designed to execute commands using SSH&lt;/h1&gt;
&lt;p&gt;currently it is not supporting Windows&lt;/p&gt;
&lt;p&gt;installlation: &lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;bash&quot;&gt;&lt;pre class=&quot;language-bash&quot;&gt;&lt;code class=&quot;language-bash&quot;&gt;&lt;span class=&quot;token function&quot;&gt;sudo&lt;/span&gt; pip &lt;span class=&quot;token function&quot;&gt;install&lt;/span&gt; ansible&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;or for mac&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;bash&quot;&gt;&lt;pre class=&quot;language-bash&quot;&gt;&lt;code class=&quot;language-bash&quot;&gt;brew &lt;span class=&quot;token function&quot;&gt;install&lt;/span&gt; ansible&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h1&gt;Vagrant newtwork&lt;/h1&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;ruby&quot;&gt;&lt;pre class=&quot;language-ruby&quot;&gt;&lt;code class=&quot;language-ruby&quot;&gt;config&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;vm&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;network &lt;span class=&quot;token string&quot;&gt;&quot;private_network&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; ip&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&quot;192.168.99.100&quot;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Add &lt;code class=&quot;language-text&quot;&gt;web.local 192.168.99.100&lt;/code&gt; to  &lt;code class=&quot;language-text&quot;&gt;/etc/hosts&lt;/code&gt;, The Vagrant machine can then be accessed using the &lt;code class=&quot;language-text&quot;&gt;web.local&lt;/code&gt; name address rather than a forwarded port address of something like &lt;code class=&quot;language-text&quot;&gt;http://localhost:8080&lt;/code&gt;&lt;/p&gt;
&lt;h2&gt;Multiple machines&lt;/h2&gt;
&lt;p&gt;The ordering and overriding of provisioners and variables is especially important in
multimachine Vagrant environments. A multimachine Vagrantfile can specify global
parameters (such as boxes or common provisioning tasks) that allow for individual
machines to override the global parameters&lt;/p&gt;
&lt;h2&gt;Important configuration&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;has_ssh&lt;/em&gt; (boolean) - If true, then Vagrant will support SSH with the container. This allows vagrant ssh to work, provisioners, etc. This defaults to false.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;link&lt;/em&gt; (method, string argument) - Link this container to another by name. The argument should be in the format of (name:alias). Example: docker.link(“db:db”). Note, if you are linking to another container in the same Vagrantfile, make sure you call vagrant up with the —no-parallel flag.&lt;/p&gt;
&lt;h1&gt;Vagrant with docker&lt;/h1&gt;
&lt;p&gt;The Docker provider does not require a Vagrant box. The config.vm.box setting is completely optional.&lt;/p&gt;
&lt;p&gt;A box can still be used and specified, however, to provide defaults. Because the Vagrantfile within a box is loaded as part of the configuration loading sequence, it can be used to configure the foundation of a development environment.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;In general, however, you will not need a box with the Docker provider.&lt;/strong&gt;&lt;/p&gt;
&lt;h1&gt;Boot2docker&lt;/h1&gt;
&lt;p&gt;Boot2docker is an excellent project that spin up docker containers in a virtual machine when the hosts (i.e. OSX) don’t support LXC, but it may be not suitable for large applications. &lt;/p&gt;
&lt;h3&gt;box with docker provider&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;phusion/ubuntu-14.04-amd64&lt;/li&gt;
&lt;li&gt;hashicorp/boot2docker&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;host-vagrant:&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Using ansible provision to install Docker onto Ubuntu&lt;/li&gt;
&lt;li&gt;Ensure Boot2Docker vm is also forward the same ports&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Plugins&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;vagrant-notify-forwarder:
By default, this sets up &lt;code class=&quot;language-text&quot;&gt;UDP port 29324&lt;/code&gt; for port forwarding&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Sync folder for docker containers in boot2docker&lt;/h2&gt;
&lt;p&gt;using &lt;code class=&quot;language-text&quot;&gt;vm.synced_folder&lt;/code&gt; to overide docker container volums&lt;/p&gt;
&lt;h2&gt;Webpack&lt;/h2&gt;
&lt;p&gt;&lt;code class=&quot;language-text&quot;&gt;watchOptions.poll&lt;/code&gt; &lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;text&quot;&gt;&lt;pre class=&quot;language-text&quot;&gt;&lt;code class=&quot;language-text&quot;&gt;poll: 1000 // Check for changes every second&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Watching does not work with NFS and machines in VirtualBox.&lt;/p&gt;
&lt;h2&gt;nodemon&lt;/h2&gt;
&lt;p&gt;&lt;code class=&quot;language-text&quot;&gt;--legacy-watch&lt;/code&gt; is needed to apply when using boot2docker to watch file changes&lt;/p&gt;</content:encoded></item><item><title><![CDATA[JavaScript Notes!]]></title><description><![CDATA[JavaScript notes comparasion Plain JavaScript pros: Does not require any additional libraries or technology Offers the best performance…]]></description><link>https://gatsby-starter-blog-demo.netlify.com/java-script-readme</link><guid isPermaLink="false">https://gatsby-starter-blog-demo.netlify.com/java-script-readme</guid><pubDate>Thu, 31 Jan 2019 00:00:00 GMT</pubDate><content:encoded>&lt;h1&gt;JavaScript notes&lt;/h1&gt;
&lt;h2&gt;comparasion&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Plain JavaScript&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;pros:&lt;/li&gt;
&lt;li&gt;Does not require any additional libraries or technology&lt;/li&gt;
&lt;li&gt;Offers the best performance&lt;/li&gt;
&lt;li&gt;Provides the best level of compatibility with third-party libraries&lt;/li&gt;
&lt;li&gt;Allows the creation of ad hoc and more advanced algorithms&lt;/li&gt;
&lt;li&gt;cons:&lt;/li&gt;
&lt;li&gt;Might require extra code and relatively complex algorithms&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Async(lib)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;pros:&lt;/li&gt;
&lt;li&gt;Simplifies the most common control flow patterns&lt;/li&gt;
&lt;li&gt;Is still a callback-based solution&lt;/li&gt;
&lt;li&gt;Good performance&lt;/li&gt;
&lt;li&gt;cons:&lt;/li&gt;
&lt;li&gt;Introduce an extreanl dependency&lt;/li&gt;
&lt;li&gt;Might still not be enough for advanced flows&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Promises&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;pros:&lt;/li&gt;
&lt;li&gt;Greatly simplifies the most common control flow patterns&lt;/li&gt;
&lt;li&gt;Robust error handling&lt;/li&gt;
&lt;li&gt;Part of the ES2015 specification&lt;/li&gt;
&lt;li&gt;Guarantees deferred invocation of onFulfilled and onRejected&lt;/li&gt;
&lt;li&gt;cons:&lt;/li&gt;
&lt;li&gt;Requires promisify callback-based APIs&lt;/li&gt;
&lt;li&gt;Intoduces a small performance hit&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Generators&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;pros:&lt;/li&gt;
&lt;li&gt;Makes non-blocking API look like a blocking one&lt;/li&gt;
&lt;li&gt;Simplifies erro handling&lt;/li&gt;
&lt;li&gt;Part of ES2015 specification&lt;/li&gt;
&lt;li&gt;cons:&lt;/li&gt;
&lt;li&gt;Requires a complementary control flow library&lt;/li&gt;
&lt;li&gt;Still requires callbacks or promises to implement non-sequential flows&lt;/li&gt;
&lt;li&gt;Requires thunkify or promisify nongenerator-bnased APIs&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Async await&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;pros:&lt;/li&gt;
&lt;li&gt;Makes non-blocking API look like blocking&lt;/li&gt;
&lt;li&gt;Clean and intuitive syntax&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Warning&lt;/h2&gt;
&lt;p&gt;With &lt;code class=&quot;language-text&quot;&gt;let&lt;/code&gt; and &lt;code class=&quot;language-text&quot;&gt;const&lt;/code&gt; in ES6, it’s no longer safe to check for an identifier’s existence using &lt;code class=&quot;language-text&quot;&gt;typeof&lt;/code&gt;:&lt;/p&gt;
&lt;h2&gt;Module&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;AMD: AMD stands for Asynchronous Module Definition. This system works in such a way that when the module is defined, usually at the moment of loading the file with the source code, it is not necessary when it is going to be used, but rather when it is available for later use in the system.&lt;/li&gt;
&lt;li&gt;CommonJS: Unlike AMD modules that are loaded asynchronously on demand, CommonJS modules are loaded synchronously&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Pure function vs impure function&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Pure function&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Must return something&lt;/li&gt;
&lt;li&gt;No matter how many times the function is executed the result should be the same if the input is also the same&lt;/li&gt;
&lt;li&gt;Input data must not be mutated during the execution of the function&lt;/li&gt;
&lt;li&gt;Not iterate over any array using for, while, do-while…&lt;/li&gt;
&lt;li&gt;Not sharing any state with other functions&lt;/li&gt;
&lt;li&gt;Implementing it should not have any side-effects in any other part of our program&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;JavaScript optimizing&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;tail call optimization:The tail call optimization improvement is that if the return line is a function, it will not deal with call stack issues.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Memoization: Memoization is the process of storing the results of expensive function calls and returning the cached result when the same inputs occur again.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;lazy loading: Consider an object that is expensive to create that is to say it takes a great deal of time to create the object. If we are unsure if the object’s value will be needed, we can defer its full creation until later.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Currying – Partial application: Currying is the technique of translating the evaluation of a function that takes multiple arguments into evaluating a sequence of functions, each with a single argument.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Composing: Composing is another benefit of functional programming allowing to generate super functions using existing functions.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;</content:encoded></item><item><title><![CDATA[Dimensionality Reduction Notes!]]></title><description><![CDATA[Dimensionality Reduction Principal component analysis (PCA) It is an unsupervised linear transformation technique that is widely used across…]]></description><link>https://gatsby-starter-blog-demo.netlify.com/machine-learning-dimensionality-reduction</link><guid isPermaLink="false">https://gatsby-starter-blog-demo.netlify.com/machine-learning-dimensionality-reduction</guid><pubDate>Thu, 31 Jan 2019 00:00:00 GMT</pubDate><content:encoded>&lt;h1&gt;Dimensionality Reduction&lt;/h1&gt;
&lt;h2&gt;Principal component analysis (PCA)&lt;/h2&gt;
&lt;p&gt;It is an unsupervised linear transformation technique that is widely used across different fields, most prominently for dimensionality reduction.&lt;/p&gt;
&lt;h2&gt;Linear Discriminant Analysis (LDA)&lt;/h2&gt;
&lt;p&gt;It can be used as a technique for feature extraction to increase the computational efficientcy and reduce the degreee of over-fitting due to the curse of dimensionality in nonregularized models.&lt;/p&gt;
&lt;h2&gt;Kernel principal component analysis&lt;/h2&gt;
&lt;p&gt;It will transform data that is not linearly separable onto a new, lower-dimensional subspace that is suitable for linear classifiers&lt;/p&gt;
&lt;p&gt;Downside: This approach is computational expesnsive, but it can be overcome by kernel trick.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Radial Basis Function (RBF)&lt;/strong&gt;&lt;/p&gt;</content:encoded></item><item><title><![CDATA[Dealling with umblanced dataset Notes!]]></title><description><![CDATA[Dealling with umblanced dataset The conventional model evaluation methods do not accurately measure model performance when faced with…]]></description><link>https://gatsby-starter-blog-demo.netlify.com/machine-learning-dealling-with-umblanced-dataset</link><guid isPermaLink="false">https://gatsby-starter-blog-demo.netlify.com/machine-learning-dealling-with-umblanced-dataset</guid><pubDate>Thu, 31 Jan 2019 00:00:00 GMT</pubDate><content:encoded>&lt;h1&gt;Dealling with umblanced dataset&lt;/h1&gt;
&lt;p&gt;The conventional model evaluation methods do not accurately measure model performance when faced with imbalanced datasets.&lt;/p&gt;
&lt;h2&gt;Collect more data&lt;/h2&gt;
&lt;h2&gt;Resampling&lt;/h2&gt;
&lt;p&gt;Standard classifier algorithms like Decision Tree and Logistic Regression have a bias towards classes which have number of instances. They tend to only predict the majority class data. The featueres of minority class are treated as noise and are often ignored. Thus, there is a high probability of misclassification of the nimority class as compared to the majority class.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Random under-sampling&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Advantages: It can help improve run time and storage problems by reducing the number of training data samples when the traing data set is huge.&lt;/li&gt;
&lt;li&gt;Disadvantages&lt;/li&gt;
&lt;li&gt;It can discard potentially useful information which could be important for building rule classifiers.&lt;/li&gt;
&lt;li&gt;The sample chosen by random under sampling may be a biased sample. And it will not be an accurate representative of the population. Thereby, resulting in inaccurate results with the actual test data set.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Random over-sampling&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Advantages:&lt;/li&gt;
&lt;li&gt;No information loss&lt;/li&gt;
&lt;li&gt;Outerperforms under sampling&lt;/li&gt;
&lt;li&gt;Disadvantages&lt;/li&gt;
&lt;li&gt;It increases the likelihood of overfitting since it replicates the minority class events&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Cluster-based over sampleing&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Advantages&lt;/li&gt;
&lt;li&gt;This clustering technique helps overcome the challenge between class imbalance. Where the number of examples representing positive class differs from the number of examples representing a negative class.&lt;/li&gt;
&lt;li&gt;Overcome challenges within class imbalance, where a class is composed of different sub clusters. And each sub cluster does not contain the same number of examples&lt;/li&gt;
&lt;li&gt;disadvanteges&lt;/li&gt;
&lt;li&gt;The main drawback of this algorithm, like most oversampling techniques is the possibility of over-fitting the traning data.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Informed over sampling: synthetic minority over-sampling technique&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Advantages&lt;/li&gt;
&lt;li&gt;Mitigates the problem of overfitting caused by random oversampling as synthetic examples are  generated rather than replication of instances&lt;/li&gt;
&lt;li&gt;No loss of useful infomation&lt;/li&gt;
&lt;li&gt;Disadvantages&lt;/li&gt;
&lt;li&gt;While generating sythetic examples SMOTE does not take into consideration neighboring examples from other classes. This can result in increase in overlapping of classes and can introduce additional noise&lt;/li&gt;
&lt;li&gt;SMOTE is not very effective for high dimensional data&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Modified synthetic minority oversampling technique (MSMOTE)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Ensemble techniques&lt;/h2&gt;</content:encoded></item><item><title><![CDATA[Cluster Analysis Notes!]]></title><description><![CDATA[Unsupervised learning - Clustering Clustering (cluser analysis) is a technique that allows us to find groups of similar objects, objects…]]></description><link>https://gatsby-starter-blog-demo.netlify.com/machine-learning-clustering-analysis</link><guid isPermaLink="false">https://gatsby-starter-blog-demo.netlify.com/machine-learning-clustering-analysis</guid><pubDate>Thu, 31 Jan 2019 00:00:00 GMT</pubDate><content:encoded>&lt;h1&gt;Unsupervised learning - Clustering&lt;/h1&gt;
&lt;p&gt;Clustering (cluser analysis) is a technique that allows us to find groups of similar objects, objects that are more related to each other than to objects in other groups.
Exaples of business-oriented applications of clustering include the grouping of documents, music, and moviews by different topics, or finding customers that share similar interests based on common purchase behaviors as a basis for recommendation egines.&lt;/p&gt;
&lt;h2&gt;k-means&lt;/h2&gt;
&lt;p&gt;It belongs to the cateory of protoype-based clustering.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Drawbacks&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;One or more clusters can be empty&lt;/li&gt;
&lt;li&gt;we have to specify the number of clusters, k, a priori&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Hard VS Soft clustering&lt;/h2&gt;
&lt;p&gt;Hard clustering: a family of algorithms where each sample in a dataset is assigned to exactly on cluster.
Soft clustering: sometimes called fuzzy clustering, it assign a sample to one or more clusters.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;fuzzy C-mean (FCM, also called soft k-means or fuzzy k-means).&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;hierachical&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;agglomerative&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;single linkage&lt;/li&gt;
&lt;li&gt;complete linkage&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;divisive clustering&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;density-based clustering&lt;/h2&gt;
&lt;p&gt;Density-based spatial Clustering of Applications with Noice (DBSCAN)&lt;/p&gt;
&lt;p&gt;Advantages:it does not assume that the clusters have a spherical shape as in k-means.&lt;/p&gt;
&lt;p&gt;Disadvantage: With an increasing number of features in our dataset -assuming a fixed number of training examples - the negative effect of curse of dimensionality increases.&lt;/p&gt;</content:encoded></item><item><title><![CDATA[Data Prepocessing Notes!]]></title><description><![CDATA[Data prepocessing Dealling with Missing data Eliminating samples or feature with missing values There are three types of missing data…]]></description><link>https://gatsby-starter-blog-demo.netlify.com/machine-learning-data-prepocessing</link><guid isPermaLink="false">https://gatsby-starter-blog-demo.netlify.com/machine-learning-data-prepocessing</guid><pubDate>Thu, 31 Jan 2019 00:00:00 GMT</pubDate><content:encoded>&lt;h1&gt;Data prepocessing&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Dealling with Missing data&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Eliminating samples or feature with missing values&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;There are three types of missing data&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Missing Completely At Random (MCAR)&lt;/li&gt;
&lt;li&gt;Missing At Random (MAR)&lt;/li&gt;
&lt;li&gt;Missing Not At Random (MNAR)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Missing categorical feature&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;KNN to predict the missing value&lt;/li&gt;
&lt;li&gt;Fill in missing values with most frequent value&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Imputing missing values&lt;/li&gt;
&lt;li&gt;Small amount value: KNN&lt;/li&gt;
&lt;li&gt;Imputer&lt;/li&gt;
&lt;li&gt;scikit-leran estimater&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Detecting outliers&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Looking as a whole: EllipticEnvelope&lt;/li&gt;
&lt;li&gt;Looking at individual feature (IQR)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Handling categorical data&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Mapping ordinal freatures&lt;/li&gt;
&lt;li&gt;Encodeing class labels&lt;/li&gt;
&lt;li&gt;Performing one-hot encoding on nominal features&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Paritioning a dataset in training and test sets&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Bringing features onto the same scale&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Selecting meaningful features&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Sparse solutions with L1 regularization&lt;/li&gt;
&lt;li&gt;Sequential freature selection algorithms&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;feature slection : select a subset of the original freatures&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Sequential Backward Selection (SBS) : reduce the dimensionality of the inital feature subspace with minimum decay in performance of the classifier to improve upon computational efficiency.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;feature extraction : derive information from the feature set to construct a new feature subspace.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Assessing feature importance with random forests&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If two or more features are highly correlated, one feature may be ranked very highly while the information fo the other feature(s) may not be fully captured. On the other hand, we don’t need to be concerned about this problem if we are merely interested in the predictive performance of a model rather than the interpretation of feature importtances.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;</content:encoded></item><item><title><![CDATA[Embedding a machine learning model to web application Notes!]]></title><description><![CDATA[Embedding a machine learning model to web application Serializing fitted scikit-learn estimaters Training a machine learning model can be…]]></description><link>https://gatsby-starter-blog-demo.netlify.com/machine-learning-embedding-model-to-webapp</link><guid isPermaLink="false">https://gatsby-starter-blog-demo.netlify.com/machine-learning-embedding-model-to-webapp</guid><pubDate>Thu, 31 Jan 2019 00:00:00 GMT</pubDate><content:encoded>&lt;h1&gt;Embedding a machine learning model to web application&lt;/h1&gt;
&lt;h2&gt;Serializing fitted scikit-learn estimaters&lt;/h2&gt;
&lt;p&gt;Training a machine learning model can be computationally quite expensive.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Model persistence (pickle): serialize and de-serialize Python object structures to compact byte code, so that we can save our classifer in its current state and reload it if we want to claasify new samples without needing to learn the modle from the training data all over again.&lt;/li&gt;
&lt;/ul&gt;</content:encoded></item><item><title><![CDATA[Ensemble learning Notes!]]></title><description><![CDATA[Ensemble learning Ensemble methods: combine different classifiers into a meta-classifier that has a better generalization performance than…]]></description><link>https://gatsby-starter-blog-demo.netlify.com/machine-learning-ensemble-learning</link><guid isPermaLink="false">https://gatsby-starter-blog-demo.netlify.com/machine-learning-ensemble-learning</guid><pubDate>Thu, 31 Jan 2019 00:00:00 GMT</pubDate><content:encoded>&lt;h1&gt;Ensemble learning&lt;/h1&gt;
&lt;p&gt;Ensemble methods: combine different classifiers into a meta-classifier that has a better generalization performance than each individual classifier alone.&lt;/p&gt;
&lt;p&gt;Example: assuming that we collected predictions from 10 experts, ensemble methods would allow us to strategically combine these predictions by the 10 experts to come up with a prediction that is more accurate and robust than the predictions by each individual expert.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Majority voting: select the class label that has been predicted by the majority of classifiers, that is, received more than 50 percent of the votes.Strictly speaking, it refers to binary class settings only.&lt;/li&gt;
&lt;li&gt;Plurality voting: select the class label that received the most votes.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Why using logistic regression and k-nearest neighbors classifier as part of pipleline?&lt;/h2&gt;
&lt;p&gt;Both algorithms(using the Euclidean distance metric) are not scale-invariant in contrast with decision trees.&lt;/p&gt;
&lt;h2&gt;Bagging ( boostrap aggregating)&lt;/h2&gt;
&lt;p&gt;The convertional baggin algorithm involves generating ‘n’ different boostrap training samples with replacement. And training the algorithm on each boostrapped algorithm separately and then aggregating the predictions at the end.&lt;/p&gt;
&lt;p&gt;Bagging is used for reducing overfitting in order to create strong learners for generating accurate predictions. Unlike boosting, baggin allows replacement in the boostrapped sample.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Advantages&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Improves stability &amp;#x26; accuracy of machine leraning algorithms&lt;/li&gt;
&lt;li&gt;Reduces variance&lt;/li&gt;
&lt;li&gt;Overcomes overfitting&lt;/li&gt;
&lt;li&gt;Improved misclassification ratre of the bagged classifier&lt;/li&gt;
&lt;li&gt;In noisy data enviroments bagging outperforms boosting&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Disavantages&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Bagging works only if the base classifers are not bad to begin with. Bagging bad classifiers can further degrade performance&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Adaptive Boosting (weak learner)&lt;/h2&gt;
&lt;p&gt;Ada Boost is the first original boosting technique which creates a highly accurate prediction rule by combining many weak and inaccurate rules. Each classifer is serially trained with the goal of correcly classifying examples in every round that were incorrectly classified in the previous round.&lt;/p&gt;
&lt;p&gt;For a learned classifier to make strong predictions, it should follow the follwing 3 conditions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The rules should be simple&lt;/li&gt;
&lt;li&gt;Classifier should have been trained on sufficient number of training examples.&lt;/li&gt;
&lt;li&gt;The classifer should have low training error for the traning instances&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Advantages&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Very simple to implement&lt;/li&gt;
&lt;li&gt;Good generalization - suited for any kind of classification problem &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Disadvantages&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Sensitive to noisy data and outliers&lt;/li&gt;
&lt;/ul&gt;</content:encoded></item></channel></rss>